#+title:
#+author: Joseph Irwin
#+property: header-args :noweb yes

* Experiments

** Preprocessing

See file:pre.py

** Feature Creation

Example feature serialization format:

: 1=global_pos_level1_slim_bigram:<N_V>

*** Feature Id Map

To format data for the classifier, assign a unique integer id to each
feature value. During training a =defaultdict= that automatically
increments a counter for each feature is used. During testing a normal
dictionary is used.

#+name: feature_dict
#+BEGIN_SRC python
def make_feature_dict():
    from collections import defaultdict
    from itertools import count
    ids = count(1)
    return defaultdict(lambda: next(ids))

def write_feature_dict(filename, feature_dict):
    with open(filename, 'w') as file:
        for f,i in sorted(feature_dict.items()):
            print('{}\t{}'.format(f,i), file=file)

def read_feature_dict(filename):
    return dict(
        (f,int(i))
        for f,i in (
                line.strip().split('\t')
                for line in open(filename)
        )
    )
#+END_SRC

*** Output Data

#+name: format_instance
#+BEGIN_SRC python
def format_instance(feats, featdict, label):
    def get(fd,k):
        try:
            return fd[k]
        except KeyError:
            return -1

    return '{label} {feats}'.format(
        label=label,
        feats=' '.join(
            '{}:{}'.format(i,v)
            for i,v in sorted([(get(featdict, f), 1) for f in feats])
            if i > 0
        )
    )
#+END_SRC

*** TODO POS Features [0/1]

- [ ] explain POS feature templates
  

#+BEGIN_SRC python :noweb-ref features
def uniq(lst):
    from itertools import groupby
    return [k for k,g in groupby(lst)]

def ngrams(seq, n=2):
    ret = []
    ngram=[]
    it = iter(seq)
    for i in it:
        ngram.append(i)
        if len(ngram) == n:
            ret.append(list(ngram))
            ngram = ngram[1:]
    return ret

def feature_format(name, value):
    return '{name}:<{value}>'.format(name=name, value=value)
#+END_SRC

#+BEGIN_SRC python :noweb-ref features
def local_pos_features(tags, tags1, tags2, tags3, boundary, postable):
    WINDOW_SIZE = 3
    fs = set()
    mkname = lambda l: 'local_pos_{0}_{1}'.format(*l)
    mkval = lambda vs: '_'.join(vs)
    def mkfeats_helper(vals, lbl):
        return (feature_format(mkname(lbl), mkval(v)) for v in vals)
    left_tags = tags[:boundary]
    right_tags = tags[boundary:]
    for i in range(1, WINDOW_SIZE + 1):
        if len(left_tags) == i:
            fs.add(feature_format('local_pos_all_left', mkval(left_tags)))
        elif len(left_tags) > i:
            fs.add(feature_format('local_pos_suffix_left', mkval(left_tags[-i:])))
        if len(right_tags) == i:
            fs.add(feature_format('local_pos_all_right', mkval(right_tags)))
        elif len(right_tags) > i:
            fs.add(feature_format('local_pos_prefix_right', mkval(right_tags[:i])))
    return fs
#+END_SRC

#+name: global_pos_features
#+BEGIN_SRC python :noweb-ref features
def global_pos_features(tags, tags1, tags2, tags3, boundary, postable):
    fs = set()

    def mkfeats_helper(vals, lbl):
        mkname = lambda l: 'global_pos_{0}_{1}_{2}gram'.format(*l)
        mkval = lambda vs: '_'.join(vs)
        return (feature_format(mkname(lbl), mkval(v)) for v in vals)
    def mkfeats(seq, typ, side, N=3):
        return [
            f
            for n,gram in ((1, 'uni'),(2, 'bi'),(3,'tri'),(4, '4-'))[:N]
            for f in mkfeats_helper(ngrams(seq, n), (typ, side, gram))
        ]
    def slim(tags):
        return [t for t in tags if t != 'X']
    def full(tags):
        return tags

    left_tags = tags[:boundary]
    right_tags = tags[boundary:]
    #level 0 (raw POS tags)
    fs.update(mkfeats(left_tags, 'level0_raw', 'left'))
    fs.update(mkfeats(right_tags, 'level0_raw', 'right'))
    #level 1
    left_l1 = uniq(tags1[:boundary])
    right_l1 = uniq(tags1[boundary:])
    # slim
    fs.update(mkfeats(uniq(slim(left_l1)), 'level1_slim', 'left'))
    fs.update(mkfeats(uniq(slim(right_l1)), 'level1_slim', 'right'))
    # full
    fs.update(mkfeats(full(left_l1), 'level1_full', 'left'))
    fs.update(mkfeats(full(right_l1), 'level1_full', 'right'))
    #level 2
    left_l2 = uniq(tags2[:boundary])
    right_l2 = uniq(tags2[boundary:])
    # slim
    fs.update(mkfeats(uniq(slim(left_l2)), 'level2_slim', 'left'))
    fs.update(mkfeats(uniq(slim(right_l2)), 'level2_slim', 'right'))
    # full
    fs.update(mkfeats(full(left_l2), 'level2_full', 'left'))
    fs.update(mkfeats(full(right_l2), 'level2_full', 'right'))
    #level 3
    left_l3 = uniq(tags3[:boundary])
    right_l3 = uniq(tags3[boundary:])
    # slim
    fs.update(mkfeats(uniq(slim(left_l3)), 'level3_slim', 'left'))
    fs.update(mkfeats(uniq(slim(right_l3)), 'level3_slim', 'right'))
    # full
    fs.update(mkfeats(full(left_l3), 'level3_full', 'left'))
    fs.update(mkfeats(full(right_l3), 'level3_full', 'right'))

    return fs
#+END_SRC

*** Script

#+BEGIN_SRC python :tangle make_data.py
#!/usr/bin/env python

<<features>>
<<feature_dict>>
<<format_instance>>

import sys

model_name = sys.argv[1]
trained_model_name = None
if len(sys.argv) > 2:
    trained_model_name = sys.argv[2]
postable_name = (trained_model_name or model_name) + '.postable'


tags = [[t for t in line.strip().split()] for line in open(model_name + '.tags')]
tags1 = [[t for t in line.strip().split()] for line in open(model_name + '.tags1')]
tags2 = [[t for t in line.strip().split()] for line in open(model_name + '.tags2')]
tags3 = [[t for t in line.strip().split()] for line in open(model_name + '.tags3')]
boundaries = [[int(b) for b in line.strip().split()] for line in open(model_name + '.boundaries')]
postable = dict( (t[0], t) for line in open(postable_name) for t in [line.strip().split()] )

feature_ids = (
    read_feature_dict(trained_model_name + '.features')
    if trained_model_name
    else make_feature_dict()
)

datafile = open(model_name + '.dat', 'w')

snum = -1
for ts,t1s,t2s,t3s, bs in zip(tags, tags1, tags2, tags3, boundaries):
    snum += 1
    for i in range(1, len(ts)):
        fs = global_pos_features(ts, t1s, t2s, t3s, i, postable)
        fs.update(local_pos_features(ts, t1s, t2s, t3s, i, postable))
        print(format_instance(fs, feature_ids, 1 if i in bs else -1), file=datafile)

datafile.close()

if not trained_model_name:
    write_feature_dict(model_name + '.features', feature_ids)
#+END_SRC

** Make constraints from classifier output

#+BEGIN_SRC python :tangle make_constraints.py
#!/usr/bin/env python

"""
make_constraints.py: Turn the classifier's output into a constraints
file to use with a parser. Outputs three files with different
threshholds for positive/negative answers.

Author: Joseph Irwin

To the extent possible under law, the person who associated CC0 with
this work has waived all copyright and related or neighboring rights
to this work.
http://creativecommons.org/publicdomain/zero/1.0/
"""

import sys


PREC_THRESH = 0.75
REC_THRESH = 0.8

model_name = sys.argv[1]
output_name = sys.argv[2]

lengths = [int(line.strip().split()[-1]) for line in open(model_name + '.boundaries')]
answers = [int(line.strip().split()[0]) for line in open(model_name + '.dat')]
outputs = [(int(row[0]), float(row[1])) for line in open(output_name) for row in [line.strip().split()]]

def filter_prec(label, score):
    if label == 1 and score > PREC_THRESH:
        return 1
    else:
        return -1

def filter_rec(label, score):
    if label == -1 and score > REC_THRESH:
        return -1
    else:
        return 1

def evaluate(ans, out):
    tp, tn, fp, fn = 0,0,0,0
    for a,o in zip(ans, out):
        if a == 1 and o == 1:
            tp += 1
        elif a == -1 and o == -1:
            tn += 1
        elif a == 1 and o == -1:
            fn += 1
        else:
            fp += 1
    acc = float(tp + tn) / sum((tp,tn,fp,fn))
    prec = float(tp) / (tp + fp)
    rec = float(tp) / (tp + fn)
    f1 = 2 * prec * rec / (prec + rec)
    return (acc, prec, rec, f1)


print("System Output:")
print("Acc:{0:.2f} Prec:{1:.2f} Rec:{2:.2f} F1:{3:.2f}".format(*evaluate(answers, (o[0] for o in outputs))))
print("Higher Precision (score > {}):".format(PREC_THRESH))
print("Acc:{0:.2f} Prec:{1:.2f} Rec:{2:.2f} F1:{3:.2f}".format(*evaluate(answers, (filter_prec(*o) for o in outputs))))
print("Higher Recall (score > {}):".format(REC_THRESH))
print("Acc:{0:.2f} Prec:{1:.2f} Rec:{2:.2f} F1:{3:.2f}".format(*evaluate(answers, (filter_rec(*o) for o in outputs))))


def make_constraints(lengths, outs):
    for l in lengths:
        os = outs[:l-1]
        outs = outs[l-1:]
        bs = [b for b,o in zip(range(1,l), os) if o == 1] + [l]
        yield bs

def dump(fname, data):
    with open(fname, 'w') as f:
        for row in data:
            print(' '.join(str(c) for c in row), file=f)

dump('constraints.default', make_constraints(lengths, [o[0] for o in outputs]))
dump('constraints.precision', make_constraints(lengths, [filter_prec(*o) for o in outputs]))
dump('constraints.recall', make_constraints(lengths, [filter_rec(*o) for o in outputs]))
#+END_SRC

** Run Stanford parser

#+BEGIN_SRC sh :tangle test-parser.sh
#!/bin/sh

DIR=$(dirname $0)
MAIN=edu.stanford.nlp.parser.lexparser.LexicalizedParser
MEM=-mx3g
TB=$1

parallel -j4 --results log "java $MEM -cp $DIR/corenlp.jar $MAIN -test $TB -indConstMinSentLen {1} -independentConstraintsFile {2} -loadFromTextFile grammar.txt" ::: 0 20 30 40 1000 ::: constraints.default constraints.precision constraints.recall test.boundaries
#+END_SRC

* Results

** Feature Evaluation

| Features            | #feats |               |   Acc |  Prec |   Rec | F_{1} | F_{0.5} |   TP |   FP |   FN |    TN |
|---------------------+--------+---------------+-------+-------+-------+-------+---------+------+------+------+-------|
| globalonly          |  33167 | default       | 87.16 | 51.69 | 83.98 | 63.99 |   55.99 | 4383 | 4097 |  836 | 29101 |
| globalonly          |  33167 | precision     | 91.64 | 85.68 | 46.22 | 60.04 |   73.18 | 2412 |  403 | 2807 | 32795 |
| globalonly          |  33167 | max precision | 90.23 | 94.20 | 29.89 | 45.38 |   65.86 | 1560 |   96 | 3659 | 33102 |
| globalonly          |  33167 | recall        | 87.16 | 51.69 | 83.98 | 63.99 |   55.99 | 4383 | 4097 |  836 | 29101 |
| localonly           |  37001 | default       | 93.71 | 80.73 | 70.49 | 75.27 |   78.45 | 3679 |  878 | 1540 | 32320 |
| localonly           |  37001 | precision     | 92.88 | 89.13 | 54.21 | 67.41 |   78.96 | 2829 |  345 | 2390 | 32853 |
| localonly           |  37001 | max precision | 90.19 | 95.26 | 29.24 | 44.74 |   65.62 | 1526 |   76 | 3693 | 33122 |
| localonly           |  37001 | recall        | 91.85 | 65.78 | 83.39 | 73.54 |   68.68 | 4352 | 2264 |  867 | 30934 |
| poslevel-all        |  82417 | default       | 95.35 | 86.89 | 77.49 | 81.92 |   84.83 | 4044 |  610 | 1175 | 32588 |
| poslevel-all        |  82417 | precision     | 94.82 | 90.35 | 69.27 | 78.42 |   85.17 | 3615 |  386 | 1604 | 32812 |
| poslevel-all        |  82417 | max precision | 91.79 | 95.11 | 41.71 | 57.99 |   75.72 | 2177 |  112 | 3042 | 33086 |
| poslevel-all        |  82417 | recall        | 93.74 | 71.51 | 89.69 | 79.58 |   74.53 | 4681 | 1865 |  538 | 31333 |
| poslevel-all-full   |  76830 | default       | 95.06 | 89.36 | 72.26 | 79.90 |   85.32 | 3771 |  449 | 1448 | 32749 |
| poslevel-all-full   |  76830 | precision     | 94.87 | 90.44 | 69.63 | 78.68 |   85.34 | 3634 |  384 | 1585 | 32814 |
| poslevel-all-full   |  76830 | max precision | 91.99 | 95.57 | 43.04 | 59.35 |   76.82 | 2246 |  104 | 2973 | 33094 |
| poslevel-all-full   |  76830 | recall        | 93.61 | 71.00 | 89.50 | 79.18 |   74.06 | 4671 | 1908 |  548 | 31290 |
| poslevel-all-slim   |  75755 | default       | 95.21 | 88.17 | 74.80 | 80.94 |   85.12 | 3904 |  524 | 1315 | 32674 |
| poslevel-all-slim   |  75755 | precision     | 94.84 | 89.85 | 69.92 | 78.64 |   85.01 | 3649 |  412 | 1570 | 32786 |
| poslevel-all-slim   |  75755 | max precision | 91.99 | 95.26 | 43.17 | 59.41 |   76.74 | 2253 |  112 | 2966 | 33086 |
| poslevel-all-slim   |  75755 | recall        | 93.53 | 70.66 | 89.60 | 79.01 |   73.77 | 4676 | 1942 |  543 | 31256 |
| poslevel0           |  70168 | default       | 95.21 | 87.38 | 75.65 | 81.09 |   84.75 | 3948 |  570 | 1271 | 32628 |
| poslevel0           |  70168 | precision     | 94.81 | 89.84 | 69.65 | 78.47 |   84.92 | 3635 |  411 | 1584 | 32787 |
| poslevel0           |  70168 | max precision | 92.48 | 94.95 | 47.15 | 63.01 |   78.94 | 2461 |  131 | 2758 | 33067 |
| poslevel0           |  70168 | recall        | 93.23 | 69.49 | 89.38 | 78.19 |   72.73 | 4665 | 2048 |  554 | 31150 |
| poslevel01          |  70222 | default       | 95.48 | 88.95 | 76.16 | 82.06 |   86.06 | 3975 |  494 | 1244 | 32704 |
| poslevel01          |  70222 | precision     | 95.18 | 90.42 | 72.20 | 80.29 |   86.08 | 3768 |  399 | 1451 | 32799 |
| poslevel01          |  70222 | max precision | 92.52 | 95.57 | 47.14 | 63.13 |   79.28 | 2460 |  114 | 2759 | 33084 |
| poslevel01          |  70222 | recall        | 93.84 | 71.73 | 90.25 | 79.93 |   74.80 | 4710 | 1856 |  509 | 31342 |
| poslevel01-full     |  70210 | default       | 95.39 | 89.25 | 75.11 | 81.57 |   86.01 | 3920 |  472 | 1299 | 32726 |
| poslevel01-full     |  70210 | precision     | 95.11 | 90.38 | 71.64 | 79.93 |   85.89 | 3739 |  398 | 1480 | 32800 |
| poslevel01-full     |  70210 | max precision | 92.51 | 95.49 | 47.06 | 63.05 |   79.19 | 2456 |  116 | 2763 | 33082 |
| poslevel01-full     |  70210 | recall        | 93.73 | 71.30 | 90.19 | 79.64 |   74.41 | 4707 | 1895 |  512 | 31303 |
| poslevel01-slim     |  70180 | default       | 95.33 | 88.79 | 75.13 | 81.39 |   85.67 | 3921 |  495 | 1298 | 32703 |
| poslevel01-slim     |  70180 | precision     | 95.03 | 90.50 | 70.84 | 79.47 |   85.74 | 3697 |  388 | 1522 | 32810 |
| poslevel01-slim     |  70180 | max precision | 92.64 | 94.76 | 48.53 | 64.19 |   79.60 | 2533 |  140 | 2686 | 33058 |
| poslevel01-slim     |  70180 | recall        | 93.64 | 71.04 | 89.73 | 79.30 |   74.13 | 4683 | 1909 |  536 | 31289 |
| poslevel02          |  72503 | default       | 95.09 | 88.28 | 73.60 | 80.27 |   84.89 | 3841 |  510 | 1378 | 32688 |
| poslevel02          |  72503 | precision     | 94.73 | 89.95 | 68.94 | 78.06 |   84.78 | 3598 |  402 | 1621 | 32796 |
| poslevel02          |  72503 | max precision | 91.76 | 95.08 | 41.50 | 57.78 |   75.57 | 2166 |  112 | 3053 | 33086 |
| poslevel02          |  72503 | recall        | 93.70 | 71.19 | 90.07 | 79.53 |   74.31 | 4701 | 1902 |  518 | 31296 |
| poslevel03          |  80028 | default       | 94.84 | 88.81 | 70.99 | 78.91 |   84.56 | 3705 |  467 | 1514 | 32731 |
| poslevel03          |  80028 | precision     | 94.69 | 89.71 | 68.81 | 77.88 |   84.57 | 3591 |  412 | 1628 | 32786 |
| poslevel03          |  80028 | max precision | 91.83 | 95.49 | 41.83 | 58.17 |   75.99 | 2183 |  103 | 3036 | 33095 |
| poslevel03          |  80028 | recall        | 93.19 | 69.44 | 89.12 | 78.06 |   72.65 | 4651 | 2047 |  568 | 31151 |
| poslevel1           |  37055 | default       | 94.81 | 78.38 | 85.38 | 81.73 |   79.69 | 4456 | 1229 |  763 | 31969 |
| poslevel1           |  37055 | precision     | 94.11 | 88.78 | 64.86 | 74.96 |   82.68 | 3385 |  428 | 1834 | 32770 |
| poslevel1           |  37055 | max precision | 91.74 | 92.94 | 42.40 | 58.24 |   75.05 | 2213 |  168 | 3006 | 33030 |
| poslevel1           |  37055 | recall        | 94.01 | 72.33 | 90.57 | 80.43 |   75.37 | 4727 | 1808 |  492 | 31390 |
| poslevel1-full      |  37043 | default       | 94.68 | 78.37 | 84.06 | 81.11 |   79.44 | 4387 | 1211 |  832 | 31987 |
| poslevel1-full      |  37043 | precision     | 93.93 | 88.69 | 63.38 | 73.93 |   82.13 | 3308 |  422 | 1911 | 32776 |
| poslevel1-full      |  37043 | max precision | 91.89 | 93.65 | 43.25 | 59.17 |   75.95 | 2257 |  153 | 2962 | 33045 |
| poslevel1-full      |  37043 | recall        | 93.79 | 71.73 | 89.65 | 79.70 |   74.72 | 4679 | 1844 |  540 | 31354 |
| poslevel1-slim      |  37013 | default       | 94.08 | 84.50 | 69.13 | 76.05 |   80.90 | 3608 |  662 | 1611 | 32536 |
| poslevel1-slim      |  37013 | precision     | 93.47 | 88.97 | 59.32 | 71.18 |   80.88 | 3096 |  384 | 2123 | 32814 |
| poslevel1-slim      |  37013 | max precision | 92.04 | 94.96 | 43.72 | 59.88 |   76.93 | 2282 |  121 | 2937 | 33077 |
| poslevel1-slim      |  37013 | recall        | 93.20 | 69.98 | 87.47 | 77.76 |   72.90 | 4565 | 1958 |  654 | 31240 |
| poslevel12          |  39390 | default       | 95.27 | 80.99 | 85.21 | 83.04 |   81.80 | 4447 | 1044 |  772 | 32154 |
| poslevel12          |  39390 | precision     | 94.72 | 90.56 | 68.21 | 77.81 |   84.99 | 3560 |  371 | 1659 | 32827 |
| poslevel12          |  39390 | max precision | 91.48 | 93.91 | 39.85 | 55.96 |   73.87 | 2080 |  135 | 3139 | 33063 |
| poslevel12          |  39390 | recall        | 94.22 | 73.43 | 90.06 | 80.90 |   76.24 | 4700 | 1701 |  519 | 31497 |
| poslevel13-slimslim |  41553 | default       | 95.44 | 89.05 | 75.74 | 81.86 |   86.03 | 3953 |  486 | 1266 | 32712 |
| poslevel13-slimslim |  41553 | precision     | 94.99 | 91.65 | 69.44 | 79.01 |   86.14 | 3624 |  330 | 1595 | 32868 |
| poslevel13-slimslim |  41553 | max precision | 92.10 | 95.80 | 43.74 | 60.06 |   77.38 | 2283 |  100 | 2936 | 33098 |
| poslevel13-slimslim |  41553 | recall        | 94.28 | 73.82 | 89.65 | 80.97 |   76.53 | 4679 | 1659 |  540 | 31539 |
| poslevel2           |  39336 | default       | 95.34 | 84.25 | 80.76 | 82.47 |   83.53 | 4215 |  788 | 1004 | 32410 |
| poslevel2           |  39336 | precision     | 94.58 | 90.58 | 67.04 | 77.05 |   84.64 | 3499 |  364 | 1720 | 32834 |
| poslevel2           |  39336 | max precision | 91.51 | 94.33 | 39.87 | 56.05 |   74.09 | 2081 |  125 | 3138 | 33073 |
| poslevel2           |  39336 | recall        | 94.02 | 72.64 | 89.77 | 80.30 |   75.52 | 4685 | 1765 |  534 | 31433 |
| poslevel2-full      |  38301 | default       | 95.35 | 83.79 | 81.59 | 82.67 |   83.34 | 4258 |  824 |  961 | 32374 |
| poslevel2-full      |  38301 | precision     | 94.58 | 90.94 | 66.74 | 76.98 |   84.79 | 3483 |  347 | 1736 | 32851 |
| poslevel2-full      |  38301 | max precision | 91.48 | 94.35 | 39.64 | 55.83 |   73.94 | 2069 |  124 | 3150 | 33074 |
| poslevel2-full      |  38301 | recall        | 94.07 | 72.98 | 89.46 | 80.38 |   75.77 | 4669 | 1729 |  550 | 31469 |
| poslevel2-slim      |  38036 | default       | 95.43 | 89.04 | 75.65 | 81.80 |   85.99 | 3948 |  486 | 1271 | 32712 |
| poslevel2-slim      |  38036 | precision     | 94.93 | 91.21 | 69.40 | 78.82 |   85.82 | 3622 |  349 | 1597 | 32849 |
| poslevel2-slim      |  38036 | max precision | 91.97 | 94.99 | 43.19 | 59.38 |   76.61 | 2254 |  119 | 2965 | 33079 |
| poslevel2-slim      |  38036 | recall        | 93.85 | 71.98 | 89.65 | 79.85 |   74.94 | 4679 | 1821 |  540 | 31377 |
| poslevel3           |  46861 | default       | 95.04 | 89.47 | 71.95 | 79.76 |   85.31 | 3755 |  442 | 1464 | 32756 |
| poslevel3           |  46861 | precision     | 94.60 | 91.15 | 66.70 | 77.03 |   84.92 | 3481 |  338 | 1738 | 32860 |
| poslevel3           |  46861 | max precision | 91.51 | 95.84 | 39.24 | 55.68 |   74.38 | 2048 |   89 | 3171 | 33109 |
| poslevel3           |  46861 | recall        | 93.71 | 71.53 | 89.16 | 79.38 |   74.47 | 4653 | 1852 |  566 | 31346 |
| poslevel3-full      |  42321 | default       | 94.99 | 90.49 | 70.55 | 79.29 |   85.65 | 3682 |  387 | 1537 | 32811 |
| poslevel3-full      |  42321 | precision     | 94.74 | 91.36 | 67.69 | 77.77 |   85.39 | 3533 |  334 | 1686 | 32864 |
| poslevel3-full      |  42321 | max precision | 91.93 | 96.17 | 42.31 | 58.76 |   76.65 | 2208 |   88 | 3011 | 33110 |
| poslevel3-full      |  42321 | recall        | 93.85 | 72.23 | 88.96 | 79.73 |   75.05 | 4643 | 1785 |  576 | 31413 |
| poslevel3-slim      |  41541 | default       | 95.20 | 90.13 | 72.62 | 80.43 |   85.98 | 3790 |  415 | 1429 | 32783 |
| poslevel3-slim      |  41541 | precision     | 94.94 | 91.74 | 68.94 | 78.72 |   86.05 | 3598 |  324 | 1621 | 32874 |
| poslevel3-slim      |  41541 | max precision | 91.91 | 96.19 | 42.12 | 58.58 |   76.54 | 2198 |   87 | 3021 | 33111 |
| poslevel3-slim      |  41541 | recall        | 93.95 | 72.44 | 89.48 | 80.06 |   75.31 | 4670 | 1777 |  549 | 31421 |

With feature notation:
| Features                     | #feats |               |   Acc |  Prec |   Rec | F_{1} | F_{0.5} |   TP |   FP |   FN |    TN |
|------------------------------+--------+---------------+-------+-------+-------+-------+---------+------+------+------+-------|
| P_{0}                        |  33167 | default       | 87.16 | 51.69 | 83.98 | 63.99 |   55.99 | 4383 | 4097 |  836 | 29101 |
| P_{0}                        |  33167 | precision     | 91.64 | 85.68 | 46.22 | 60.04 |   73.18 | 2412 |  403 | 2807 | 32795 |
| P_{0}                        |  33167 | max precision | 90.23 | 94.20 | 29.89 | 45.38 |   65.86 | 1560 |   96 | 3659 | 33102 |
| P_{0}                        |  33167 | recall        | 87.16 | 51.69 | 83.98 | 63.99 |   55.99 | 4383 | 4097 |  836 | 29101 |
| p                            |  37001 | default       | 93.71 | 80.73 | 70.49 | 75.27 |   78.45 | 3679 |  878 | 1540 | 32320 |
| p                            |  37001 | precision     | 92.88 | 89.13 | 54.21 | 67.41 |   78.96 | 2829 |  345 | 2390 | 32853 |
| p                            |  37001 | max precision | 90.19 | 95.26 | 29.24 | 44.74 |   65.62 | 1526 |   76 | 3693 | 33122 |
| p                            |  37001 | recall        | 91.85 | 65.78 | 83.39 | 73.54 |   68.68 | 4352 | 2264 |  867 | 30934 |
| p,P_{0},P_{1},P_{2},P_{3}    |  82417 | default       | 95.35 | 86.89 | 77.49 | 81.92 |   84.83 | 4044 |  610 | 1175 | 32588 |
| p,P_{0},P_{1},P_{2},P_{3}    |  82417 | precision     | 94.82 | 90.35 | 69.27 | 78.42 |   85.17 | 3615 |  386 | 1604 | 32812 |
| p,P_{0},P_{1},P_{2},P_{3}    |  82417 | max precision | 91.79 | 95.11 | 41.71 | 57.99 |   75.72 | 2177 |  112 | 3042 | 33086 |
| p,P_{0},P_{1},P_{2},P_{3}    |  82417 | recall        | 93.74 | 71.51 | 89.69 | 79.58 |   74.53 | 4681 | 1865 |  538 | 31333 |
| p,P_{0},P_{1f},P_{2f},P_{3f} |  76830 | default       | 95.06 | 89.36 | 72.26 | 79.90 |   85.32 | 3771 |  449 | 1448 | 32749 |
| p,P_{0},P_{1f},P_{2f},P_{3f} |  76830 | precision     | 94.87 | 90.44 | 69.63 | 78.68 |   85.34 | 3634 |  384 | 1585 | 32814 |
| p,P_{0},P_{1f},P_{2f},P_{3f} |  76830 | max precision | 91.99 | 95.57 | 43.04 | 59.35 |   76.82 | 2246 |  104 | 2973 | 33094 |
| p,P_{0},P_{1f},P_{2f},P_{3f} |  76830 | recall        | 93.61 | 71.00 | 89.50 | 79.18 |   74.06 | 4671 | 1908 |  548 | 31290 |
| p,P_{0},P_{1s},P_{2s},P_{3s} |  75755 | default       | 95.21 | 88.17 | 74.80 | 80.94 |   85.12 | 3904 |  524 | 1315 | 32674 |
| p,P_{0},P_{1s},P_{2s},P_{3s} |  75755 | precision     | 94.84 | 89.85 | 69.92 | 78.64 |   85.01 | 3649 |  412 | 1570 | 32786 |
| p,P_{0},P_{1s},P_{2s},P_{3s} |  75755 | max precision | 91.99 | 95.26 | 43.17 | 59.41 |   76.74 | 2253 |  112 | 2966 | 33086 |
| p,P_{0},P_{1s},P_{2s},P_{3s} |  75755 | recall        | 93.53 | 70.66 | 89.60 | 79.01 |   73.77 | 4676 | 1942 |  543 | 31256 |
| p,P_{0}                      |  70168 | default       | 95.21 | 87.38 | 75.65 | 81.09 |   84.75 | 3948 |  570 | 1271 | 32628 |
| p,P_{0}                      |  70168 | precision     | 94.81 | 89.84 | 69.65 | 78.47 |   84.92 | 3635 |  411 | 1584 | 32787 |
| p,P_{0}                      |  70168 | max precision | 92.48 | 94.95 | 47.15 | 63.01 |   78.94 | 2461 |  131 | 2758 | 33067 |
| p,P_{0}                      |  70168 | recall        | 93.23 | 69.49 | 89.38 | 78.19 |   72.73 | 4665 | 2048 |  554 | 31150 |
| p,P_{0},P_{1}                |  70222 | default       | 95.48 | 88.95 | 76.16 | 82.06 |   86.06 | 3975 |  494 | 1244 | 32704 |
| p,P_{0},P_{1}                |  70222 | precision     | 95.18 | 90.42 | 72.20 | 80.29 |   86.08 | 3768 |  399 | 1451 | 32799 |
| p,P_{0},P_{1}                |  70222 | max precision | 92.52 | 95.57 | 47.14 | 63.13 |   79.28 | 2460 |  114 | 2759 | 33084 |
| p,P_{0},P_{1}                |  70222 | recall        | 93.84 | 71.73 | 90.25 | 79.93 |   74.80 | 4710 | 1856 |  509 | 31342 |
| p,P_{0},P_{1f}               |  70210 | default       | 95.39 | 89.25 | 75.11 | 81.57 |   86.01 | 3920 |  472 | 1299 | 32726 |
| p,P_{0},P_{1f}               |  70210 | precision     | 95.11 | 90.38 | 71.64 | 79.93 |   85.89 | 3739 |  398 | 1480 | 32800 |
| p,P_{0},P_{1f}               |  70210 | max precision | 92.51 | 95.49 | 47.06 | 63.05 |   79.19 | 2456 |  116 | 2763 | 33082 |
| p,P_{0},P_{1f}               |  70210 | recall        | 93.73 | 71.30 | 90.19 | 79.64 |   74.41 | 4707 | 1895 |  512 | 31303 |
| p,P_{0},P_{1s}               |  70180 | default       | 95.33 | 88.79 | 75.13 | 81.39 |   85.67 | 3921 |  495 | 1298 | 32703 |
| p,P_{0},P_{1s}               |  70180 | precision     | 95.03 | 90.50 | 70.84 | 79.47 |   85.74 | 3697 |  388 | 1522 | 32810 |
| p,P_{0},P_{1s}               |  70180 | max precision | 92.64 | 94.76 | 48.53 | 64.19 |   79.60 | 2533 |  140 | 2686 | 33058 |
| p,P_{0},P_{1s}               |  70180 | recall        | 93.64 | 71.04 | 89.73 | 79.30 |   74.13 | 4683 | 1909 |  536 | 31289 |
| p,P_{0},P_{2}                |  72503 | default       | 95.09 | 88.28 | 73.60 | 80.27 |   84.89 | 3841 |  510 | 1378 | 32688 |
| p,P_{0},P_{2}                |  72503 | precision     | 94.73 | 89.95 | 68.94 | 78.06 |   84.78 | 3598 |  402 | 1621 | 32796 |
| p,P_{0},P_{2}                |  72503 | max precision | 91.76 | 95.08 | 41.50 | 57.78 |   75.57 | 2166 |  112 | 3053 | 33086 |
| p,P_{0},P_{2}                |  72503 | recall        | 93.70 | 71.19 | 90.07 | 79.53 |   74.31 | 4701 | 1902 |  518 | 31296 |
| p,P_{0},P_{3}                |  80028 | default       | 94.84 | 88.81 | 70.99 | 78.91 |   84.56 | 3705 |  467 | 1514 | 32731 |
| p,P_{0},P_{3}                |  80028 | precision     | 94.69 | 89.71 | 68.81 | 77.88 |   84.57 | 3591 |  412 | 1628 | 32786 |
| p,P_{0},P_{3}                |  80028 | max precision | 91.83 | 95.49 | 41.83 | 58.17 |   75.99 | 2183 |  103 | 3036 | 33095 |
| p,P_{0},P_{3}                |  80028 | recall        | 93.19 | 69.44 | 89.12 | 78.06 |   72.65 | 4651 | 2047 |  568 | 31151 |
| p,P_{1}                      |  37055 | default       | 94.81 | 78.38 | 85.38 | 81.73 |   79.69 | 4456 | 1229 |  763 | 31969 |
| p,P_{1}                      |  37055 | precision     | 94.11 | 88.78 | 64.86 | 74.96 |   82.68 | 3385 |  428 | 1834 | 32770 |
| p,P_{1}                      |  37055 | max precision | 91.74 | 92.94 | 42.40 | 58.24 |   75.05 | 2213 |  168 | 3006 | 33030 |
| p,P_{1}                      |  37055 | recall        | 94.01 | 72.33 | 90.57 | 80.43 |   75.37 | 4727 | 1808 |  492 | 31390 |
| p,P_{1f}                     |  37043 | default       | 94.68 | 78.37 | 84.06 | 81.11 |   79.44 | 4387 | 1211 |  832 | 31987 |
| p,P_{1f}                     |  37043 | precision     | 93.93 | 88.69 | 63.38 | 73.93 |   82.13 | 3308 |  422 | 1911 | 32776 |
| p,P_{1f}                     |  37043 | max precision | 91.89 | 93.65 | 43.25 | 59.17 |   75.95 | 2257 |  153 | 2962 | 33045 |
| p,P_{1f}                     |  37043 | recall        | 93.79 | 71.73 | 89.65 | 79.70 |   74.72 | 4679 | 1844 |  540 | 31354 |
| p,P_{1s}                     |  37013 | default       | 94.08 | 84.50 | 69.13 | 76.05 |   80.90 | 3608 |  662 | 1611 | 32536 |
| p,P_{1s}                     |  37013 | precision     | 93.47 | 88.97 | 59.32 | 71.18 |   80.88 | 3096 |  384 | 2123 | 32814 |
| p,P_{1s}                     |  37013 | max precision | 92.04 | 94.96 | 43.72 | 59.88 |   76.93 | 2282 |  121 | 2937 | 33077 |
| p,P_{1s}                     |  37013 | recall        | 93.20 | 69.98 | 87.47 | 77.76 |   72.90 | 4565 | 1958 |  654 | 31240 |
| p,P_{1},P_{2}                |  39390 | default       | 95.27 | 80.99 | 85.21 | 83.04 |   81.80 | 4447 | 1044 |  772 | 32154 |
| p,P_{1},P_{2}                |  39390 | precision     | 94.72 | 90.56 | 68.21 | 77.81 |   84.99 | 3560 |  371 | 1659 | 32827 |
| p,P_{1},P_{2}                |  39390 | max precision | 91.48 | 93.91 | 39.85 | 55.96 |   73.87 | 2080 |  135 | 3139 | 33063 |
| p,P_{1},P_{2}                |  39390 | recall        | 94.22 | 73.43 | 90.06 | 80.90 |   76.24 | 4700 | 1701 |  519 | 31497 |
| p,P_{1s},P_{3s}              |  41553 | default       | 95.44 | 89.05 | 75.74 | 81.86 |   86.03 | 3953 |  486 | 1266 | 32712 |
| p,P_{1s},P_{3s}              |  41553 | precision     | 94.99 | 91.65 | 69.44 | 79.01 |   86.14 | 3624 |  330 | 1595 | 32868 |
| p,P_{1s},P_{3s}              |  41553 | max precision | 92.10 | 95.80 | 43.74 | 60.06 |   77.38 | 2283 |  100 | 2936 | 33098 |
| p,P_{1s},P_{3s}              |  41553 | recall        | 94.28 | 73.82 | 89.65 | 80.97 |   76.53 | 4679 | 1659 |  540 | 31539 |
| p,P_{2}                      |  39336 | default       | 95.34 | 84.25 | 80.76 | 82.47 |   83.53 | 4215 |  788 | 1004 | 32410 |
| p,P_{2}                      |  39336 | precision     | 94.58 | 90.58 | 67.04 | 77.05 |   84.64 | 3499 |  364 | 1720 | 32834 |
| p,P_{2}                      |  39336 | max precision | 91.51 | 94.33 | 39.87 | 56.05 |   74.09 | 2081 |  125 | 3138 | 33073 |
| p,P_{2}                      |  39336 | recall        | 94.02 | 72.64 | 89.77 | 80.30 |   75.52 | 4685 | 1765 |  534 | 31433 |
| p,P_{2f}                     |  38301 | default       | 95.35 | 83.79 | 81.59 | 82.67 |   83.34 | 4258 |  824 |  961 | 32374 |
| p,P_{2f}                     |  38301 | precision     | 94.58 | 90.94 | 66.74 | 76.98 |   84.79 | 3483 |  347 | 1736 | 32851 |
| p,P_{2f}                     |  38301 | max precision | 91.48 | 94.35 | 39.64 | 55.83 |   73.94 | 2069 |  124 | 3150 | 33074 |
| p,P_{2f}                     |  38301 | recall        | 94.07 | 72.98 | 89.46 | 80.38 |   75.77 | 4669 | 1729 |  550 | 31469 |
| p,P_{2s}                     |  38036 | default       | 95.43 | 89.04 | 75.65 | 81.80 |   85.99 | 3948 |  486 | 1271 | 32712 |
| p,P_{2s}                     |  38036 | precision     | 94.93 | 91.21 | 69.40 | 78.82 |   85.82 | 3622 |  349 | 1597 | 32849 |
| p,P_{2s}                     |  38036 | max precision | 91.97 | 94.99 | 43.19 | 59.38 |   76.61 | 2254 |  119 | 2965 | 33079 |
| p,P_{2s}                     |  38036 | recall        | 93.85 | 71.98 | 89.65 | 79.85 |   74.94 | 4679 | 1821 |  540 | 31377 |
| p,P_{3}                      |  46861 | default       | 95.04 | 89.47 | 71.95 | 79.76 |   85.31 | 3755 |  442 | 1464 | 32756 |
| p,P_{3}                      |  46861 | precision     | 94.60 | 91.15 | 66.70 | 77.03 |   84.92 | 3481 |  338 | 1738 | 32860 |
| p,P_{3}                      |  46861 | max precision | 91.51 | 95.84 | 39.24 | 55.68 |   74.38 | 2048 |   89 | 3171 | 33109 |
| p,P_{3}                      |  46861 | recall        | 93.71 | 71.53 | 89.16 | 79.38 |   74.47 | 4653 | 1852 |  566 | 31346 |
| p,P_{3f}                     |  42321 | default       | 94.99 | 90.49 | 70.55 | 79.29 |   85.65 | 3682 |  387 | 1537 | 32811 |
| p,P_{3f}                     |  42321 | precision     | 94.74 | 91.36 | 67.69 | 77.77 |   85.39 | 3533 |  334 | 1686 | 32864 |
| p,P_{3f}                     |  42321 | max precision | 91.93 | 96.17 | 42.31 | 58.76 |   76.65 | 2208 |   88 | 3011 | 33110 |
| p,P_{3f}                     |  42321 | recall        | 93.85 | 72.23 | 88.96 | 79.73 |   75.05 | 4643 | 1785 |  576 | 31413 |
| p,P_{3s}                     |  41541 | default       | 95.20 | 90.13 | 72.62 | 80.43 |   85.98 | 3790 |  415 | 1429 | 32783 |
| p,P_{3s}                     |  41541 | precision     | 94.94 | 91.74 | 68.94 | 78.72 |   86.05 | 3598 |  324 | 1621 | 32874 |
| p,P_{3s}                     |  41541 | max precision | 91.91 | 96.19 | 42.12 | 58.58 |   76.54 | 2198 |   87 | 3021 | 33111 |
| p,P_{3s}                     |  41541 | recall        | 93.95 | 72.44 | 89.48 | 80.06 |   75.31 | 4670 | 1777 |  549 | 31421 |
** Parser Evaluation

*** Linear Classifier

Features: $p$, $P_{0}$, $P_{1}$
|    0 | constraints.default   | 1283.0 | 13296177914 | 10796797207 | 83.71 |  15 |
|    0 | constraints.precision | 1143.3 | 13570188752 | 11279769316 | 84.05 |   7 |
|    0 | constraints.recall    | 1024.8 | 12313400101 |  7801130588 | 78.74 | 136 |
|    0 | constraints.maxprec   | 1384.4 | 15271396915 | 14218032860 | 85.55 |   2 |
|    0 | test.boundaries       | 1013.0 | 12164963359 |  8470948033 | 86.71 |   4 |
|   20 | constraints.default   | 1126.9 | 13816900881 | 11174754845 | 84.17 |   9 |
|   20 | constraints.precision | 1313.0 | 14065494867 | 11636746870 | 84.43 |   4 |
|   20 | constraints.recall    | 1121.8 | 12912619374 |  8241531200 | 80.38 | 103 |
|   20 | constraints.maxprec   | 1338.6 | 15580050079 | 14429123051 | 85.59 |   2 |
|   20 | test.boundaries       | 1044.8 | 12756095006 |  8897890529 | 86.55 |   2 |
|   30 | constraints.default   | 1312.3 | 15090653479 | 12761229652 | 84.82 |   3 |
|   30 | constraints.precision | 1279.7 | 15264708152 | 13125902773 | 85.01 |   1 |
|   30 | constraints.recall    | 1140.5 | 14419385879 | 10200308890 | 82.79 |  57 |
|   30 | constraints.maxprec   | 1485.9 | 16250828052 | 15280942284 | 85.63 |   1 |
|   30 | test.boundaries       | 1125.8 | 14252188350 | 10753841131 | 86.33 |   0 |
|   40 | constraints.default   | 1476.8 | 16399407345 | 15126587300 | 85.56 |   1 |
|   40 | constraints.precision | 1390.9 | 16452028661 | 15246049993 | 85.59 |   0 |
|   40 | constraints.recall    | 1403.9 | 15924910329 | 13328329995 | 84.65 |  14 |
|   40 | constraints.maxprec   | 1513.3 | 16900594853 | 16455972255 | 85.75 |   0 |
|   40 | test.boundaries       | 1359.5 | 15955429934 | 13931989846 | 86.04 |   0 |
| 1000 | constraints.default   | 1563.7 | 17247848869 | 17466541935 | 85.85 |   0 |
| 1000 | constraints.precision | 1558.7 | 17247848869 | 17466541935 | 85.85 |   0 |
| 1000 | constraints.recall    | 1481.3 | 17247848869 | 17466541935 | 85.85 |   0 |
| 1000 | constraints.maxprec   | 1489.8 | 17247848869 | 17466541935 | 85.85 |   0 |
| 1000 | test.boundaries       | 1270.3 | 17247848869 | 17466541935 | 85.85 |   0 |


| SentLen | Constraints           | time(s) |  #rules |     |  #edges |     |   F_1 |       |
|---------+-----------------------+---------+---------+-----+---------+-----+-------+-------|
|       0 | constraints.default   |  1283.0 | 1.33e10 |  77 | 1.08e10 |  62 | 83.71 | -2.14 |
|       0 | constraints.precision |  1143.3 | 1.36e10 |  79 | 1.13e10 |  65 | 84.05 | -1.80 |
|       0 | constraints.recall    |  1024.8 | 1.23e10 |  72 | 7.80e09 |  45 | 78.74 | -7.11 |
|       0 | constraints.maxprec   |  1384.4 | 1.53e10 |  89 | 1.42e10 |  81 | 85.55 | -0.30 |
|       0 | test.boundaries       |  1013.0 | 1.22e10 |  71 | 8.47e09 |  48 | 86.71 |  0.86 |
|      20 | constraints.default   |  1126.9 | 1.38e10 |  80 | 1.12e10 |  64 | 84.17 | -1.68 |
|      20 | constraints.precision |  1313.0 | 1.41e10 |  82 | 1.16e10 |  66 | 84.43 | -1.42 |
|      20 | constraints.recall    |  1121.8 | 1.29e10 |  75 | 8.24e09 |  47 | 80.38 | -5.47 |
|      20 | constraints.maxprec   |  1338.6 | 1.56e10 |  91 | 1.44e10 |  82 | 85.59 | -0.26 |
|      20 | test.boundaries       |  1044.8 | 1.28e10 |  74 | 8.90e09 |  51 | 86.55 |  0.70 |
|      30 | constraints.default   |  1312.3 | 1.51e10 |  88 | 1.28e10 |  73 | 84.82 | -1.03 |
|      30 | constraints.precision |  1279.7 | 1.53e10 |  89 | 1.31e10 |  75 | 85.01 | -0.84 |
|      30 | constraints.recall    |  1140.5 | 1.44e10 |  84 | 1.02e10 |  58 | 82.79 | -3.06 |
|      30 | constraints.maxprec   |  1485.9 | 1.63e10 |  95 | 1.53e10 |  87 | 85.63 | -0.22 |
|      30 | test.boundaries       |  1125.8 | 1.43e10 |  83 | 1.08e10 |  62 | 86.33 |  0.48 |
|      40 | constraints.default   |  1476.8 | 1.64e10 |  95 | 1.51e10 |  86 | 85.56 | -0.29 |
|      40 | constraints.precision |  1390.9 | 1.65e10 |  96 | 1.52e10 |  87 | 85.59 | -0.26 |
|      40 | constraints.recall    |  1403.9 | 1.59e10 |  92 | 1.33e10 |  76 | 84.65 | -1.20 |
|      40 | constraints.maxprec   |  1513.3 | 1.69e10 |  98 | 1.65e10 |  94 | 85.75 | -0.10 |
|      40 | test.boundaries       |  1359.5 | 1.60e10 |  93 | 1.39e10 |  79 | 86.04 |  0.19 |
|    1000 | constraints.default   |  1563.7 | 1.72e10 | 100 | 1.75e10 | 100 | 85.85 |  0.00 |
|    1000 | constraints.precision |  1558.7 | 1.72e10 | 100 | 1.75e10 | 100 | 85.85 |  0.00 |
|    1000 | constraints.recall    |  1481.3 | 1.72e10 | 100 | 1.75e10 | 100 | 85.85 |  0.00 |
|    1000 | constraints.maxprec   |  1489.8 | 1.72e10 | 100 | 1.75e10 | 100 | 85.85 |  0.00 |
|    1000 | test.boundaries       |  1270.3 | 1.72e10 | 100 | 1.75e10 | 100 | 85.85 |  0.00 |

*** Linear Classifier 2

Features: p, P_1s, P_3s

|    0 | constraints.default   | 1119.1 | 13316958817 | 10768961378 | 83.79 |  5 |
|    0 | constraints.precision | 1245.7 | 13842288667 | 11657560320 | 84.68 |  2 |
|    0 | constraints.recall    | 1007.6 | 11964170969 |  7510974952 | 78.78 | 95 |
|    0 | constraints.maxprec   | 1389.8 | 15576369500 | 14842456458 | 85.72 |  0 |
|    0 | test.boundaries       | 1016.8 | 12164963359 |  8470948033 | 86.71 |  4 |
|   20 | constraints.default   | 1278.8 | 13854603558 | 11159762325 |  84.2 |  2 |
|   20 | constraints.precision | 1227.1 | 14330995855 | 12006728014 | 84.89 |  2 |
|   20 | constraints.recall    |  998.3 | 12561604126 |  7959701888 | 80.34 | 57 |
|   20 | constraints.maxprec   | 1439.6 | 15861950827 | 15036761915 | 85.78 |  0 |
|   20 | test.boundaries       | 1054.6 | 12756095006 |  8897890529 | 86.55 |  2 |
|   30 | constraints.default   | 1277.4 | 15111663336 | 12704523363 | 84.86 |  0 |
|   30 | constraints.precision | 1307.1 | 15385507328 | 13310327353 | 85.19 |  0 |
|   30 | constraints.recall    | 1116.3 | 14107120181 |  9930495929 | 82.75 | 26 |
|   30 | constraints.maxprec   | 1476.1 | 16440202343 | 15747939325 | 85.75 |  0 |
|   30 | test.boundaries       | 1152.9 | 14252188350 | 10753841131 | 86.33 |  0 |
|   40 | constraints.default   | 1509.7 | 16381293071 | 15038933828 | 85.48 |  0 |
|   40 | constraints.precision | 1357.5 | 16494416016 | 15323478757 |  85.7 |  0 |
|   40 | constraints.recall    | 1404.5 | 15869684025 | 13345856748 | 84.86 |  8 |
|   40 | constraints.maxprec   | 1507.5 | 16971806883 | 16674505777 | 85.83 |  0 |
|   40 | test.boundaries       | 1344.4 | 15955429934 | 13931989846 | 86.04 |  0 |
| 1000 | constraints.default   | 1528.3 | 17247848869 | 17466541935 | 85.85 |  0 |
| 1000 | constraints.precision | 1501.3 | 17247848869 | 17466541935 | 85.85 |  0 |
| 1000 | constraints.recall    | 1503.5 | 17247848869 | 17466541935 | 85.85 |  0 |
| 1000 | constraints.maxprec   | 1550.9 | 17247848869 | 17466541935 | 85.85 |  0 |
| 1000 | test.boundaries       | 1292.9 | 17247848869 | 17466541935 | 85.85 |  0 |


| SentLen | Constraints   | time(s) |   #rules |     |   #edges |     |   F_1 |       | #failed |
|---------+---------------+---------+----------+-----+----------+-----+-------+-------+---------|
|       0 | default       |  1119.1 | 1.33e+10 |  77 | 1.08e+10 |  62 | 83.79 | -2.06 |       5 |
|       0 | precision     |  1245.7 | 1.38e+10 |  80 | 1.17e+10 |  67 | 84.68 | -1.17 |       2 |
|       0 | recall        |  1007.6 | 1.20e+10 |  70 | 7.51e+09 |  43 | 78.78 | -7.07 |      95 |
|       0 | max precision |  1389.8 | 1.56e+10 |  91 | 1.48e+10 |  85 | 85.72 | -0.13 |       0 |
|       0 | oracle        |  1016.8 | 1.22e+10 |  71 | 8.47e+09 |  48 | 86.71 |  0.86 |       4 |
|      20 | default       |  1278.8 | 1.39e+10 |  81 | 1.12e+10 |  64 |  84.2 | -1.65 |       2 |
|      20 | precision     |  1227.1 | 1.43e+10 |  83 | 1.20e+10 |  69 | 84.89 | -0.96 |       2 |
|      20 | recall        |   998.3 | 1.26e+10 |  73 | 7.96e+09 |  45 | 80.34 | -5.51 |      57 |
|      20 | max precision |  1439.6 | 1.59e+10 |  92 | 1.50e+10 |  86 | 85.78 | -0.07 |       0 |
|      20 | oracle        |  1054.6 | 1.28e+10 |  74 | 8.90e+09 |  51 | 86.55 |  0.70 |       2 |
|      30 | default       |  1277.4 | 1.51e+10 |  88 | 1.27e+10 |  73 | 84.86 | -0.99 |       0 |
|      30 | precision     |  1307.1 | 1.54e+10 |  90 | 1.33e+10 |  76 | 85.19 | -0.66 |       0 |
|      30 | recall        |  1116.3 | 1.41e+10 |  82 | 9.93e+09 |  57 | 82.75 | -3.10 |      26 |
|      30 | max precision |  1476.1 | 1.64e+10 |  95 | 1.57e+10 |  90 | 85.75 | -0.10 |       0 |
|      30 | oracle        |  1152.9 | 1.43e+10 |  83 | 1.08e+10 |  62 | 86.33 |  0.48 |       0 |
|      40 | default       |  1509.7 | 1.64e+10 |  95 | 1.50e+10 |  86 | 85.48 | -0.37 |       0 |
|      40 | precision     |  1357.5 | 1.65e+10 |  96 | 1.53e+10 |  87 |  85.7 | -0.15 |       0 |
|      40 | recall        |  1404.5 | 1.59e+10 |  92 | 1.33e+10 |  76 | 84.86 | -0.99 |       8 |
|      40 | max precision |  1507.5 | 1.70e+10 |  99 | 1.67e+10 |  95 | 85.83 | -0.02 |       0 |
|      40 | oracle        |  1344.4 | 1.60e+10 |  93 | 1.39e+10 |  79 | 86.04 |  0.19 |       0 |
|    1000 | default       |  1528.3 | 1.72e+10 | 100 | 1.75e+10 | 100 | 85.85 |  0.00 |       0 |
|    1000 | precision     |  1501.3 | 1.72e+10 | 100 | 1.75e+10 | 100 | 85.85 |  0.00 |       0 |
|    1000 | recall        |  1503.5 | 1.72e+10 | 100 | 1.75e+10 | 100 | 85.85 |  0.00 |       0 |
|    1000 | max precision |  1550.9 | 1.72e+10 | 100 | 1.75e+10 | 100 | 85.85 |  0.00 |       0 |
|    1000 | oracle        |  1292.9 | 1.72e+10 | 100 | 1.75e+10 | 100 | 85.85 |  0.00 |       0 |
#+TBLFM: $4=$0;%.2e::$5=$4*100/1.72e10;%.0f::$6=$0;%.2e::$7=$6*100/1.75e10;%.0f::$9=$8-85.85;p4%.2f

*** Polynomial Kernel (d=3)

Features: All

|    0 | constraints.default   | 1106.7 | 12683027145 |  9735735691 | 84.85 |  6 |
|    0 | constraints.precision | 1118.8 | 12760600352 |  9836301542 | 85.12 |  4 |
|    0 | constraints.recall    | 1050.7 | 12453000568 |  9250088732 | 84.05 | 33 |
|    0 | constraints.maxprec   | 1137.2 | 13012418542 | 10184849050 | 85.42 |  2 |
|    0 | test.boundaries       | 1060.3 | 12164963359 |  8470948033 | 86.71 |  4 |
|   20 | constraints.default   | 1070.7 | 13277526839 | 10159758409 | 85.08 |  5 |
|   20 | constraints.precision | 1172.4 | 13344483151 | 10253461736 | 85.25 |  3 |
|   20 | constraints.recall    | 1088.3 | 13046796495 |  9678204621 | 84.75 |  7 |
|   20 | constraints.maxprec   | 1092.4 | 13544977656 | 10569389626 | 85.41 |  2 |
|   20 | test.boundaries       | 1073.1 | 12756095006 |  8897890529 | 86.55 |  2 |
|   30 | constraints.default   | 1222.6 | 14740725049 | 11963246655 | 85.57 |  1 |
|   30 | constraints.precision | 1267.5 | 14786205417 | 12026201090 | 85.62 |  1 |
|   30 | constraints.recall    | 1238.0 | 14570207705 | 11565056730 | 85.44 |  2 |
|   30 | constraints.maxprec   | 1238.7 | 14915843061 | 12257798935 | 85.65 |  1 |
|   30 | test.boundaries       | 1165.9 | 14252188350 | 10753841131 | 86.33 |  0 |
|   40 | constraints.default   | 1465.4 | 16305015517 | 14881781272 | 85.72 |  0 |
|   40 | constraints.precision | 1353.3 | 16311169191 | 14889440831 | 85.75 |  0 |
|   40 | constraints.recall    | 1489.7 | 16224613497 | 14675616015 | 85.69 |  1 |
|   40 | constraints.maxprec   | 1570.2 | 16366619373 | 14992213821 | 85.78 |  0 |
|   40 | test.boundaries       | 1476.0 | 15955429934 | 13931989846 | 86.04 |  0 |
| 1000 | constraints.default   | 1469.2 | 17247848869 | 17466541935 | 85.85 |  0 |
| 1000 | constraints.precision | 1471.1 | 17247848869 | 17466541935 | 85.85 |  0 |
| 1000 | constraints.recall    | 1470.9 | 17247848869 | 17466541935 | 85.85 |  0 |
| 1000 | constraints.maxprec   | 1398.4 | 17247848869 | 17466541935 | 85.85 |  0 |
| 1000 | test.boundaries       | 1222.6 | 17247848869 | 17466541935 | 85.85 |  0 |


| SentLen | Constraints           | time(s) |  #rules |     |  #edges |     |   F_1 |       |
|---------+-----------------------+---------+---------+-----+---------+-----+-------+-------|
|       0 | constraints.default   |  1106.7 | 1.27e10 |  74 | 9.74e09 |  56 | 84.85 | -1.00 |
|       0 | constraints.precision |  1118.8 | 1.28e10 |  74 | 9.84e09 |  56 | 85.12 | -0.73 |
|       0 | constraints.recall    |  1050.7 | 1.25e10 |  73 | 9.25e09 |  53 | 84.05 | -1.80 |
|       0 | constraints.maxprec   |  1137.2 | 1.30e10 |  76 | 1.02e10 |  58 | 85.42 | -0.43 |
|       0 | test.boundaries       |  1060.3 | 1.22e10 |  71 | 8.47e09 |  48 | 86.71 |  0.86 |
|      20 | constraints.default   |  1070.7 | 1.33e10 |  77 | 1.02e10 |  58 | 85.08 | -0.77 |
|      20 | constraints.precision |  1172.4 | 1.33e10 |  77 | 1.03e10 |  59 | 85.25 | -0.60 |
|      20 | constraints.recall    |  1088.3 | 1.30e10 |  76 | 9.68e09 |  55 | 84.75 | -1.10 |
|      20 | constraints.maxprec   |  1092.4 | 1.35e10 |  78 | 1.06e10 |  61 | 85.41 | -0.44 |
|      20 | test.boundaries       |  1073.1 | 1.28e10 |  74 | 8.90e09 |  51 | 86.55 |  0.70 |
|      30 | constraints.default   |  1222.6 | 1.47e10 |  86 | 1.20e10 |  69 | 85.57 | -0.28 |
|      30 | constraints.precision |  1267.5 | 1.48e10 |  86 | 1.20e10 |  69 | 85.62 | -0.23 |
|      30 | constraints.recall    |  1238.0 | 1.46e10 |  85 | 1.16e10 |  66 | 85.44 | -0.41 |
|      30 | constraints.maxprec   |  1238.7 | 1.49e10 |  87 | 1.23e10 |  70 | 85.65 | -0.20 |
|      30 | test.boundaries       |  1165.9 | 1.43e10 |  83 | 1.08e10 |  62 | 86.33 |  0.48 |
|      40 | constraints.default   |  1465.4 | 1.63e10 |  95 | 1.49e10 |  85 | 85.72 | -0.13 |
|      40 | constraints.precision |  1353.3 | 1.63e10 |  95 | 1.49e10 |  85 | 85.75 | -0.10 |
|      40 | constraints.recall    |  1489.7 | 1.62e10 |  94 | 1.47e10 |  84 | 85.69 | -0.16 |
|      40 | constraints.maxprec   |  1570.2 | 1.64e10 |  95 | 1.50e10 |  86 | 85.78 | -0.07 |
|      40 | test.boundaries       |  1476.0 | 1.60e10 |  93 | 1.39e10 |  79 | 86.04 |  0.19 |
|    1000 | constraints.default   |  1469.2 | 1.72e10 | 100 | 1.75e10 | 100 | 85.85 |  0.00 |
|    1000 | constraints.precision |  1471.1 | 1.72e10 | 100 | 1.75e10 | 100 | 85.85 |  0.00 |
|    1000 | constraints.recall    |  1470.9 | 1.72e10 | 100 | 1.75e10 | 100 | 85.85 |  0.00 |
|    1000 | constraints.maxprec   |  1398.4 | 1.72e10 | 100 | 1.75e10 | 100 | 85.85 |  0.00 |
|    1000 | test.boundaries       |  1222.6 | 1.72e10 | 100 | 1.75e10 | 100 | 85.85 |  0.00 |

*** WSJ23

**** Linear
pP1sP3s

| base1  | 1508.1 | 85.54 |
| base2  | 1527.7 | 85.54 |
| base3  | 1567.1 | 85.54 |
| const1 | 1101.2 | 83.55 |
| const2 | 1113.3 | 83.55 |
| const3 | 1104.1 | 83.55 |

#+BEGIN_EXAMPLE
==> base.err1 <==
 P: 100.0 R: 100.0
factor LP/LR F1: 100.0 N: 2416.0
 P: 100.0 R: 100.0
factor Tag F1: 100.0 N: 2416.0

Testing on treebank done [1508.1 sec].
pcfg LP/LR summary evalb: LP: 86.09 LR: 84.99 F1: 85.54 Exact: 28.76 N: 2416
dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0
factor LP/LR summary evalb: LP: 86.09 LR: 84.99 F1: 85.54 Exact: 28.76 N: 2416
factor Tag summary evalb: LP: 96.76 LR: 96.76 F1: 96.76 Exact: 51.98 N: 2416

==> base.err2 <==
 P: 100.0 R: 100.0
factor LP/LR F1: 100.0 N: 2416.0
 P: 100.0 R: 100.0
factor Tag F1: 100.0 N: 2416.0

Testing on treebank done [1527.7 sec].
pcfg LP/LR summary evalb: LP: 86.09 LR: 84.99 F1: 85.54 Exact: 28.76 N: 2416
dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0
factor LP/LR summary evalb: LP: 86.09 LR: 84.99 F1: 85.54 Exact: 28.76 N: 2416
factor Tag summary evalb: LP: 96.76 LR: 96.76 F1: 96.76 Exact: 51.98 N: 2416

==> base.err3 <==
 P: 100.0 R: 100.0
factor LP/LR F1: 100.0 N: 2416.0
 P: 100.0 R: 100.0
factor Tag F1: 100.0 N: 2416.0

Testing on treebank done [1567.1 sec].
pcfg LP/LR summary evalb: LP: 86.09 LR: 84.99 F1: 85.54 Exact: 28.76 N: 2416
dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0
factor LP/LR summary evalb: LP: 86.09 LR: 84.99 F1: 85.54 Exact: 28.76 N: 2416
factor Tag summary evalb: LP: 96.76 LR: 96.76 F1: 96.76 Exact: 51.98 N: 2416

==> const.err1 <==
 P: 58.33 R: 70.0
factor LP/LR F1: 63.63 N: 2416.0
 P: 100.0 R: 100.0
factor Tag F1: 100.0 N: 2416.0

Testing on treebank done [1101.2 sec].
pcfg LP/LR summary evalb: LP: 84.02 LR: 83.08 F1: 83.55 Exact: 26.53 N: 2416
dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0
factor LP/LR summary evalb: LP: 84.02 LR: 83.08 F1: 83.55 Exact: 26.53 N: 2416
factor Tag summary evalb: LP: 96.53 LR: 96.53 F1: 96.53 Exact: 50.12 N: 2416

==> const.err2 <==
 P: 58.33 R: 70.0
factor LP/LR F1: 63.63 N: 2416.0
 P: 100.0 R: 100.0
factor Tag F1: 100.0 N: 2416.0

Testing on treebank done [1113.3 sec].
pcfg LP/LR summary evalb: LP: 84.02 LR: 83.08 F1: 83.55 Exact: 26.53 N: 2416
dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0
factor LP/LR summary evalb: LP: 84.02 LR: 83.08 F1: 83.55 Exact: 26.53 N: 2416
factor Tag summary evalb: LP: 96.53 LR: 96.53 F1: 96.53 Exact: 50.12 N: 2416

==> const.err3 <==
 P: 58.33 R: 70.0
factor LP/LR F1: 63.63 N: 2416.0
 P: 100.0 R: 100.0
factor Tag F1: 100.0 N: 2416.0

Testing on treebank done [1104.1 sec].
pcfg LP/LR summary evalb: LP: 84.02 LR: 83.08 F1: 83.55 Exact: 26.53 N: 2416
dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0
factor LP/LR summary evalb: LP: 84.02 LR: 83.08 F1: 83.55 Exact: 26.53 N: 2416
factor Tag summary evalb: LP: 96.53 LR: 96.53 F1: 96.53 Exact: 50.12 N: 2416
#+END_EXAMPLE

**** Poly
All

| base1  | 1579.5 | 85.54 |
| base2  | 1525.8 | 85.54 |
| base3  | 1521.9 | 85.54 |
| const1 | 1019.8 | 84.57 |
| const2 | 1043.1 | 84.57 |
| const3 | 1058.6 | 84.57 |

#+BEGIN_EXAMPLE
==> base.err1 <==
 P: 100.0 R: 100.0
factor LP/LR F1: 100.0 N: 2416.0
 P: 100.0 R: 100.0
factor Tag F1: 100.0 N: 2416.0

Testing on treebank done [1579.5 sec].
pcfg LP/LR summary evalb: LP: 86.09 LR: 84.99 F1: 85.54 Exact: 28.76 N: 2416
dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0
factor LP/LR summary evalb: LP: 86.09 LR: 84.99 F1: 85.54 Exact: 28.76 N: 2416
factor Tag summary evalb: LP: 96.76 LR: 96.76 F1: 96.76 Exact: 51.98 N: 2416

==> base.err2 <==
 P: 100.0 R: 100.0
factor LP/LR F1: 100.0 N: 2416.0
 P: 100.0 R: 100.0
factor Tag F1: 100.0 N: 2416.0

Testing on treebank done [1525.8 sec].
pcfg LP/LR summary evalb: LP: 86.09 LR: 84.99 F1: 85.54 Exact: 28.76 N: 2416
dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0
factor LP/LR summary evalb: LP: 86.09 LR: 84.99 F1: 85.54 Exact: 28.76 N: 2416
factor Tag summary evalb: LP: 96.76 LR: 96.76 F1: 96.76 Exact: 51.98 N: 2416

==> base.err3 <==
 P: 100.0 R: 100.0
factor LP/LR F1: 100.0 N: 2416.0
 P: 100.0 R: 100.0
factor Tag F1: 100.0 N: 2416.0

Testing on treebank done [1521.9 sec].
pcfg LP/LR summary evalb: LP: 86.09 LR: 84.99 F1: 85.54 Exact: 28.76 N: 2416
dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0
factor LP/LR summary evalb: LP: 86.09 LR: 84.99 F1: 85.54 Exact: 28.76 N: 2416
factor Tag summary evalb: LP: 96.76 LR: 96.76 F1: 96.76 Exact: 51.98 N: 2416

==> const.err1 <==
 P: 100.0 R: 100.0
factor LP/LR F1: 100.0 N: 2416.0
 P: 100.0 R: 100.0
factor Tag F1: 100.0 N: 2416.0

Testing on treebank done [1019.8 sec].
pcfg LP/LR summary evalb: LP: 85.12 LR: 84.03 F1: 84.57 Exact: 26.69 N: 2416
dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0
factor LP/LR summary evalb: LP: 85.12 LR: 84.03 F1: 84.57 Exact: 26.69 N: 2416
factor Tag summary evalb: LP: 96.62 LR: 96.62 F1: 96.62 Exact: 51.2 N: 2416

==> const.err2 <==
 P: 100.0 R: 100.0
factor LP/LR F1: 100.0 N: 2416.0
 P: 100.0 R: 100.0
factor Tag F1: 100.0 N: 2416.0

Testing on treebank done [1043.1 sec].
pcfg LP/LR summary evalb: LP: 85.12 LR: 84.03 F1: 84.57 Exact: 26.69 N: 2416
dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0
factor LP/LR summary evalb: LP: 85.12 LR: 84.03 F1: 84.57 Exact: 26.69 N: 2416
factor Tag summary evalb: LP: 96.62 LR: 96.62 F1: 96.62 Exact: 51.2 N: 2416

==> const.err3 <==
 P: 100.0 R: 100.0
factor LP/LR F1: 100.0 N: 2416.0
 P: 100.0 R: 100.0
factor Tag F1: 100.0 N: 2416.0

Testing on treebank done [1058.6 sec].
pcfg LP/LR summary evalb: LP: 85.12 LR: 84.03 F1: 84.57 Exact: 26.69 N: 2416
dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0
factor LP/LR summary evalb: LP: 85.12 LR: 84.03 F1: 84.57 Exact: 26.69 N: 2416
factor Tag summary evalb: LP: 96.62 LR: 96.62 F1: 96.62 Exact: 51.2 N: 2416
#+END_EXAMPLE
