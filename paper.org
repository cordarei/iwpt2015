#+title: CKY Parsing With Independence Constraints
#+author: Joseph Irwin
#+OPTIONS: H:2 toc:nil _:{}
#+LATEX_CLASS: acl2015
#+LATEX_HEADER: \usepackage{forest}
#+LATEX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LATEX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \newcommand{\BigO}[1]{\ensuremath{\operatorname{O}\bigl(#1\bigr)}}

# file:paper.pdf

#+BEGIN_LaTeX
\begin{abstract}
We propose a novel property of words in a sentence, derived from a
context-free derivation, and show how this property can be used to
reduce the computation done by the CKY algorithm. We demonstrate a
classifier which can be used to identify boundaries between
independent words in a sentence using only surface features, and show
that it can be used to speed up a CFG parser.
\end{abstract}
#+END_LaTeX

* Introduction

Syntactic parsing, in particular constituent parsing with context-free
grammars extracted from treebanks, is used in a wide variety of tasks
and applications. The CKY algorithm often appears as the whole or a part
of the implementation of CFG parsers and of so-called “deep” parsers.
Although CKY with a small grammar may be cheap in comparison to a later
step, it may be difficult to assert that it is “fast enough.” To that
end, various approaches to reducing the computation done by the CKY
algorithm by compromising on exhaustiveness and/or exactness have been
explored.

It is possible to add various kinds of constraints without altering
the basic CKY algorithm. These mostly involve deciding beforehand
whether or not a certain span or kind of span can or cannot exist in
the chart.

We propose a novel type of top-down constraint for a CFG parser that
we call independence constraints, described in Section 2. In Section 3
we show how the CKY algorithm can be easily modified to accomodate
these constraints, and in Section 4 we describe a classifier which can
provide the constraints to a parser. We integrete the constraints into
the Stanford Parser CKY implementation and show the results in Section 5.

* Independence Constraints

We propose a concept we call *independence*. Given a sentence $s = w_1
w_2 \dots w_n$ and a context-free derivation (parse tree) $t$ of $s$,
$w_i$ and $w_{i+1}$ are *independent* if every node in $t$ that
dominates both $w_i$ and $w_{i+1}$ also dominates $w_1$ and $w_n$.
Furthermore, if $w_i$ and $w_{i+1}$ are independent, then $\forall
j,k$ s.t. $j \leq i$ and $k > i$, $w_j$ and $w_k$ are independent.
Less formally, if the children of the top node of a parse tree are
split into separate subtrees, two words are independent if they would
end up in different subtrees.

#+BEGIN_LaTeX
\begin{figure}
\begin{forest}
  [S
   [NP [DT [ $_0$ This $_1$]]]
   [VP
    [VB [is $_2$]]
    [NP [DT [an $_3$]]
        [NN [example $_4$]]]]
   [{.} [{.} $_5$]]
  ]
\end{forest}
\caption{In this tree ‘This’ and ‘is’ are independent, while ‘is’ and ‘an’ are not.}
\label{fig:independence}
\end{figure}
#+END_LaTeX

An example is shown in Figure \ref{fig:independence}. Here, ‘This’ and
‘is’ are independent, [0,1), [1, 4), and [4, 5) are the independent
spans, and 1 and 4 are the independent span boundaries. The
independent spans and independent span boundaries can be derived
straightforwardly from the definition of independent words: the
locations between consecutive words which are independent are the
independent span boundaries, and the independent spans are simply the
spans in between consecutive boundaries.

* Modifying The CKY Algorithm With Independence Constraints

Conceptually, the motivation for the concept of independence is this:
an independent span can be parsed independently, without reference to
anything outside it. If a CKY parser knows the locations of the
independent span boundaries for a sentence, it can perform the normal
CKY algorithm for each independent span separately, and simply join
the spans at the top of the tree to finish the parse, thereby avoiding
work which would otherwise be done while still obtaining the desired
1-best parse. Two problems make the task more complicated than this.

The first problem is that if we assume that the independent boundaries
will be identified automatically, we must allow for errors. If a
location which is not an independent span boundary is given as one,
the parser will make an error it would not have otherwise. On the
other hand, if a location which is an independent span boundary is not
marked as such, the parser may account for this at the cost of not
achieving the minimum computation possible. By allowing for this
second type of error, the algorithm is made more robust, and allows
the independent boundary identification step to prioritize precision
over recall to lessen negative impact on the parser’s accuracy.

The second problem is caused by the binarization of the context-free
grammar used in the CKY algorithm. Because the CKY algorithm requires
a binary grammar, any rules in the original grammar that have more
than two symbols on the right-hand side must be converted into a
sequence of binary rules. The extra rules created in this process are
called incomplete or synthetic rules. The topmost span in particular
will usually need to be constructed in several steps; however, the
bottom-up nature of the algorithm means that it is impossible to
determine whether a given synthetic rule at any position in the CKY
chart will eventually be used to construct a complete span at the top
of the tree (for arbitrary grammars—if the grammar is left- or
right-binarized, only cells on the left or right edge of the chart can
effect the top span).

The combination of these two issues means that in order to correctly
parse a sentence when an independent span boundary is missing from the
input the modified CKY algorithm must process synthetic rules even at
positions in the chart that cross a boundary.

Thus in the modified algorithm, cells which do not cross an
independent boundary are processed normally, and in cells which do
cross a boundary the algorithm will avoid looping over complete
binary rules. While boundary-crossing cells depend on non-crossing
cells, the reverse is not the case; thus the non-crossing cells can
all be processed before the crossing cells, or the cells can be looped
over in the regular order, with a check inside the loop. Although
checking inside the loop adds at least one branch and is thus less
efficient, the difference is probably minor.

** TODO expected work saved
we can consider two ideal scenarios:
  - with one constraint at N/K
  - K constraints N/K words apart

* Classifying Independent Span Boundaries

In order to use independence constraints in a parser, we need to be
able to identify boundaries between independent words in a sentence
using only surface features (words and part-of-speech tags). We
created a binary classifier which, given a POS-tagged sentence and a
position between two words, decides whether those two words are
independent or not. Our classifier currently uses only POS tags as
features. We used =opal=, a tool for fast online classification, to
train and test the models, training on sentences from Penn Treebank
section 02-21 and testing on section 22. We set opal to use the
passive-aggressive perceptron update, and output probabilities in
order to use a threshold to trade off precision and recall.

** Features

We use only part-of-speech tags to create features for the classifier
(adding lexical or other features is left to future work). The
property of independence between two words is inherently global, as it
can be affected by structure arbitrarily far away. Thus we have both
local and global features. The global features are furthermore
distinguished by *POS level*, explained in detail later. The specific
feature templates are shown below:

*** Local Features
**** Left
- $t_{k-1}$
- $t_{k-2},t_{k-1}$
- $t_{k-3},t_{k-2},t_{k-1}$

**** Right
- $t_{k}$
- $t_{k},t_{k+1}$
- $t_{k},t_{k+1},t_{k+2}$

*** Global Features

Below, $t^{l}_{i}$ is the $i$ th POS tag in the $l$-level POS tag sequence.

**** Left
- $t^l_{i}$ for $1 \le i < k - 1$, $l \in {0,1,2,3}$
- $t^l_{i},t^l_{i+1}$ for $1 \le i < k - 2$, $l \in {0,1,2,3}$
- $t^l_{i},t^l_{i+1},t^l_{i+2}$ for $1 \le i < k - 3$, $l \in {0,1,2,3}$

**** Right
- $t^l_{i}$ for $k \le i < n - 1$, $l \in {0,1,2,3}$
- $t^l_{i},t^l_{i+1}$ for $k \le i < n - 2$, $l \in {0,1,2,3}$
- $t^l_{i},t^l_{i+1},t^l_{i+2}$ for $k \le i < n - 3$, $l \in {0,1,2,3}$

*** POS Level

In previous unpublished work on a similar task, we found that
heuristically transforming the POS tag sequence to create additional
features can be beneficial. We refer to these transformations as *POS
levels*. In this classifier we implemented three levels, in addition
to the original POS tags as level 0.

We show all levels in table \ref{tbl:pos-level}. Each level specifies
a value by which each level 0 tag is replaced during the
transformation. Each transformation has three variations: 's', where
'X's are removed from the sequence prior to extracting n-gram
features; 'f', where they are not; and the default variation which
creates features from both.

The motivation behind each transformation is roughly as follows: level
1 is meant to capture clause nuclei; level 2 is further intended to
show boundaries between clauses; and level 3 expands almost all the
way back to the original tags, but with some distinctions erased,
mostly to reduce the number of features.

#+BEGIN_LaTeX
\begin{table}[tbp]
\tiny
#+END_LaTeX

#+attr_latex: :center nil
| Lvl0 | Lvl1 | Lvl2 | Lvl3 |   | Lvl0  | Lvl1 | Lvl2 | Lvl3 |
|------+------+------+------+---+-------+------+------+------|
| NN   | N    | N    | N    |   | CD    | X    | X    | #    |
| NNP  | N    | N    | N    |   | -LRB- | X    | X    | B    |
| NNPS | N    | N    | N    |   | -RRB- | X    | X    | B    |
| NNS  | N    | N    | N    |   | DT    | X    | X    | D    |
| PRP  | N    | N    | N    |   | PDT   | X    | X    | D    |
| VB   | V    | V    | V    |   | PRP$  | X    | X    | D    |
| VBD  | V    | V    | V    |   | WP$   | X    | X    | D    |
| VBG  | V    | V    | V    |   | JJ    | X    | X    | J    |
| VBN  | V    | V    | V    |   | JJR   | X    | X    | J    |
| VBP  | V    | V    | V    |   | JJS   | X    | X    | J    |
| VBZ  | V    | V    | V    |   | -RQ-  | X    | X    | Q    |
| ,    | X    | ,    | ,    |   | -LQ-  | X    | X    | Q    |
| .    | X    | .    | .    |   | RB    | X    | X    | R    |
| :    | X    | :    | :    |   | RBR   | X    | X    | R    |
| CC   | X    | C    | C    |   | RBS   | X    | X    | R    |
| IN   | X    | I    | I    |   | EX    | X    | X    | X    |
| RP   | X    | I    | I    |   | FW    | X    | X    | X    |
| TO   | X    | T    | T    |   | LS    | X    | X    | X    |
| WDT  | X    | W    | W    |   | MD    | X    | X    | X    |
| WP   | X    | W    | W    |   | POS   | X    | X    | X    |
| WRB  | X    | W    | W    |   | SYM   | X    | X    | X    |
| #    | X    | X    | #    |   | UH    | X    | X    | X    |
| $    | X    | X    | #    |   |       |      |      |      |

#+BEGIN_LaTeX
\caption{For each POS level, the original tag is replaced with the corresponding value.}
\label{tbl:pos-level}
\end{table}
#+END_LaTeX

** Which Features Are Useful?

#+BEGIN_LaTeX
\begin{table*}[tbp]
%\resizebox{12cm}{!}{
#+END_LaTeX

#+attr_latex: :center nil
| Features                     | #feats |     Acc |    Prec |     Rec |   F_{1} | F_{0.5} |   TP |   FP |   FN |    TN |
|------------------------------+--------+---------+---------+---------+---------+---------+------+------+------+-------|
| p                            |  37001 |   93.71 |   80.73 |   70.49 |   75.27 |   78.45 | 3679 |  878 | 1540 | 32320 |
| P_{0}                        |  33167 |   87.16 |   51.69 |   83.98 |   63.99 |   55.99 | 4383 | 4097 |  836 | 29101 |
|------------------------------+--------+---------+---------+---------+---------+---------+------+------+------+-------|
| p,P_{0}                      |  70168 |   95.21 |   87.38 |   75.65 |   81.09 |   84.75 | 3948 |  570 | 1271 | 32628 |
| p,P_{0},P_{1}                |  70222 | *95.48* |   88.95 |   76.16 |   82.06 | *86.06* | 3975 |  494 | 1244 | 32704 |
| p,P_{0},P_{1f}               |  70210 |   95.39 |   89.25 |   75.11 |   81.57 |   86.01 | 3920 |  472 | 1299 | 32726 |
| p,P_{0},P_{1s}               |  70180 |   95.33 |   88.79 |   75.13 |   81.39 |   85.67 | 3921 |  495 | 1298 | 32703 |
| p,P_{0},P_{2}                |  72503 |   95.09 |   88.28 |   73.60 |   80.27 |   84.89 | 3841 |  510 | 1378 | 32688 |
| p,P_{0},P_{3}                |  80028 |   94.84 |   88.81 |   70.99 |   78.91 |   84.56 | 3705 |  467 | 1514 | 32731 |
|------------------------------+--------+---------+---------+---------+---------+---------+------+------+------+-------|
| p,P_{0},P_{1},P_{2},P_{3}    |  82417 |   95.35 |   86.89 |   77.49 |   81.92 |   84.83 | 4044 |  610 | 1175 | 32588 |
| p,P_{0},P_{1f},P_{2f},P_{3f} |  76830 |   95.06 |   89.36 |   72.26 |   79.90 |   85.32 | 3771 |  449 | 1448 | 32749 |
| p,P_{0},P_{1s},P_{2s},P_{3s} |  75755 |   95.21 |   88.17 |   74.80 |   80.94 |   85.12 | 3904 |  524 | 1315 | 32674 |
|------------------------------+--------+---------+---------+---------+---------+---------+------+------+------+-------|
| p,P_{1}                      |  37055 |   94.81 |   78.38 | *85.38* |   81.73 |   79.69 | 4456 | 1229 |  763 | 31969 |
| p,P_{1f}                     |  37043 |   94.68 |   78.37 |   84.06 |   81.11 |   79.44 | 4387 | 1211 |  832 | 31987 |
| p,P_{1s}                     |  37013 |   94.08 |   84.50 |   69.13 |   76.05 |   80.90 | 3608 |  662 | 1611 | 32536 |
| p,P_{1},P_{2}                |  39390 |   95.27 |   80.99 |   85.21 | *83.04* |   81.80 | 4447 | 1044 |  772 | 32154 |
| p,P_{1s},P_{3s}              |  41553 | *95.44* |   89.05 |   75.74 |   81.86 | *86.03* | 3953 |  486 | 1266 | 32712 |
|------------------------------+--------+---------+---------+---------+---------+---------+------+------+------+-------|
| p,P_{2}                      |  39336 |   95.34 |   84.25 |   80.76 |   82.47 |   83.53 | 4215 |  788 | 1004 | 32410 |
| p,P_{2f}                     |  38301 |   95.35 |   83.79 |   81.59 |   82.67 |   83.34 | 4258 |  824 |  961 | 32374 |
| p,P_{2s}                     |  38036 |   95.43 |   89.04 |   75.65 |   81.80 |   85.99 | 3948 |  486 | 1271 | 32712 |
|------------------------------+--------+---------+---------+---------+---------+---------+------+------+------+-------|
| p,P_{3}                      |  46861 |   95.04 |   89.47 |   71.95 |   79.76 |   85.31 | 3755 |  442 | 1464 | 32756 |
| p,P_{3f}                     |  42321 |   94.99 | *90.49* |   70.55 |   79.29 |   85.65 | 3682 |  387 | 1537 | 32811 |
| p,P_{3s}                     |  41541 |   95.20 |   90.13 |   72.62 |   80.43 |   85.98 | 3790 |  415 | 1429 | 32783 |

#+BEGIN_LaTeX
%}
\caption{Results of classifier using different combinations of features.}
\label{tbl:feature-evaluation}
\end{table*}
#+END_LaTeX

In order to find the best configuration of features for the
classifier, and to evaluate the proposed POS levels, we tested the
classifier using several different combinations. Selected results are
shown in table \ref{tbl:feature-evaluation}. In the "Features" column,
$p$ denotes the local features, and $P_{l}$ denotes the global
features from POS level $l$. The 's' and 'f' after the number
indicates a variation which includes ('f') or excludes ('s') the 'X'
tags before taking the n-grams; absence of 's' or 'f' means both types
are created.

There are several things worth noting in these results. First, neither
local nor global features are sufficient alone; it appears that local
features promote precision, while global features promote recall.
Second, examining the cases where global features are limited to a
single POS level, it is apparent that each POS level (and 's'/'f'
variant) has a different effect on precision and recall, thus
confirming that the classifier is able to extract different signals
from the different POS levels, as intended. Finally, combining all POS
levels together actually reduces accuracy, likely due to overfitting
(although see the discussion of the kernel classifier).

** Results

#+BEGIN_LaTeX
\begin{table*}[htbp]
%\resizebox{12cm}{!}{
#+END_LaTeX

#+attr_latex: :center nil
| Features        | #feats | Threshold     |   Acc |  Prec |   Rec | F_{1} | F_{0.5} |   TP |   FP |   FN |    TN |
|-----------------+--------+---------------+-------+-------+-------+-------+---------+------+------+------+-------|
| p,P_{1s},P_{3s} |  41553 | default       | 95.44 | 89.05 | 75.74 | 81.86 |   86.03 | 3953 |  486 | 1266 | 32712 |
| p,P_{1s},P_{3s} |  41553 | precision     | 94.99 | 91.65 | 69.44 | 79.01 |   86.14 | 3624 |  330 | 1595 | 32868 |
| p,P_{1s},P_{3s} |  41553 | max precision | 92.10 | 95.80 | 43.74 | 60.06 |   77.38 | 2283 |  100 | 2936 | 33098 |
| p,P_{1s},P_{3s} |  41553 | recall        | 94.28 | 73.82 | 89.65 | 80.97 |   76.53 | 4679 | 1659 |  540 | 31539 |

#+BEGIN_LaTeX
%}
\caption{Results of classifier using different score thresholds.}
\label{tbl:classifier-results-linear}
\end{table*}
#+END_LaTeX

\label{sec:linear-classifier}
For use as input to the parser, we select the $p,P_{1s},P_{3s}$
feature configuration, and show more detailed results in
table \ref{tbl:classifier-results-linear}. We used a threshold on the
score output by the classifier to reverse some of the classifier's
decisions in a post-process step. Although it doesn't improve on the
classifier in accuracy, the =precision= threshold did slightly improve in
F_{0.5}, a measure which favors precision over recall.

** Polynomial Kernel

#+BEGIN_LaTeX
\begin{table*}[htbp]
%\resizebox{12cm}{!}{
#+END_LaTeX

#+attr_latex: :center nil
| Features                  | #feats |               |   Acc |  Prec |   Rec | F_{1} | F_{0.5} |   TP |  FP |   FN |    TN |
|---------------------------+--------+---------------+-------+-------+-------+-------+---------+------+-----+------+-------|
| p,P_{0},P_{1},P_{2},P_{3} |  82417 | default       | 97.47 | 92.17 | 88.91 | 90.51 |   91.50 | 4640 | 394 |  579 | 32804 |
| p,P_{0},P_{1},P_{2},P_{3} |  82417 | precision     | 97.27 | 92.95 | 86.43 | 89.58 |   91.57 | 4511 | 342 |  708 | 32856 |
| p,P_{0},P_{1},P_{2},P_{3} |  82417 | max precision | 96.57 | 94.22 | 79.63 | 86.31 |   90.89 | 4156 | 255 | 1063 | 32943 |
| p,P_{0},P_{1},P_{2},P_{3} |  82417 | recall        | 97.15 | 88.16 | 91.32 | 89.71 |   88.78 | 4766 | 640 |  453 | 32558 |

#+BEGIN_LaTeX
%}
\caption{Results of polynomial classifier using different score thresholds.}
\label{tbl:classifier-results-poly}
\end{table*}
#+END_LaTeX

\label{sec:poly-classifier}
For comparison with the linear classifier, we trained another
classifier using a polynomial kernel (with degree 3) with all the
features. The results are shown in table
\ref{tbl:classifier-results-poly}. The polynomial kernel improves over
the linear classifier in accuracy by 2%, in precision by 3 points, and
in recall by just over 13 points. This suggests that there is a large
potential for improving the linear classifier by adding conjunctive
features. The polynomial classifier is not practical for use as a
preprocessing step in a parser, as it takes over 2 hours to run on
section 22 (training the model took almost 4 days).


* Parsing With Independence Constraints
In order to demonstrate use of the independent constraints in a
parser, we modified the CKY parser included in the Stanford Parser
distribution to accept independent span boundaries as constraints and
to use the modified CKY algorithm described above. Our modifications
are:

- after reading in the grammar, index the synthetic binary rules
- read in the file containing the boundaries output by the classifier
  from the previous section
- for each CKY cell, if the cell spans a boundary then loop over just
  the synthetic binary rules
- if at the end of the CKY loop a parse was not successful, then loop
  again over just the cells which span a boundary and process all of
  the binary rules
- output the total number of times entering the inner loop as well as the
  number of times the parser failed

** Experimental Setup

We use the modified Stanford Parser described above, with a grammar
extracted from the WSJ sections 02-21, and evaluate its performance on
section 22 using output from the clasifier as constraints. We vary the
threshold on the probability output by the classifier, and further
experiment with restricting the constraints to sentences above a
certain length. Finally, to compare with previous results we run the
classifier and parser on section 23 in a single configuration.

** Results

#+BEGIN_LaTeX
\begin{table*}[tbp]
%\resizebox{12cm}{!}{
#+END_LaTeX

#+attr_latex: :center nil
| SentLen | Constraints   | (P/R/F_{1})         | time(s) |  #edges |                      |   F_1 | $\Delta F_1$ | #failed parses |
|---------+---------------+---------------------+---------+---------+----------------------+-------+--------------+----------------|
|       0 | default       | (88.95/76.16/82.06) |  1283.0 | 1.08e10 | \hspace{-1em} (62%)  | 83.71 |        -2.14 |             15 |
|       0 | precision     | (90.42/72.20/80.29) |  1143.3 | 1.13e10 | \hspace{-1em} (65%)  | 84.05 |        -1.80 |              7 |
|       0 | max precision | (95.57/47.14/63.13) |  1384.4 | 1.42e10 | \hspace{-1em} (81%)  | 85.55 |        -0.30 |              2 |
|       0 | recall        | (71.73/90.25/79.93) |  1024.8 | 7.80e09 | \hspace{-1em} (45%)  | 78.74 |        -7.11 |            136 |
|      20 | default       | (88.95/76.16/82.06) |  1126.9 | 1.12e10 | \hspace{-1em} (64%)  | 84.17 |        -1.68 |              9 |
|      20 | precision     | (90.42/72.20/80.29) |  1313.0 | 1.16e10 | \hspace{-1em} (66%)  | 84.43 |        -1.42 |              4 |
|      20 | max precision | (95.57/47.14/63.13) |  1338.6 | 1.44e10 | \hspace{-1em} (82%)  | 85.59 |        -0.26 |              2 |
|      20 | recall        | (71.73/90.25/79.93) |  1121.8 | 8.24e09 | \hspace{-1em} (47%)  | 80.38 |        -5.47 |            103 |
|      30 | default       | (88.95/76.16/82.06) |  1312.3 | 1.28e10 | \hspace{-1em} (73%)  | 84.82 |        -1.03 |              3 |
|      30 | precision     | (90.42/72.20/80.29) |  1279.7 | 1.31e10 | \hspace{-1em} (75%)  | 85.01 |        -0.84 |              1 |
|      30 | max precision | (95.57/47.14/63.13) |  1485.9 | 1.53e10 | \hspace{-1em} (87%)  | 85.63 |        -0.22 |              1 |
|      30 | recall        | (71.73/90.25/79.93) |  1140.5 | 1.02e10 | \hspace{-1em} (58%)  | 82.79 |        -3.06 |             57 |
|      40 | default       | (88.95/76.16/82.06) |  1476.8 | 1.51e10 | \hspace{-1em} (86%)  | 85.56 |        -0.29 |              1 |
|      40 | precision     | (90.42/72.20/80.29) |  1390.9 | 1.52e10 | \hspace{-1em} (87%)  | 85.59 |        -0.26 |              0 |
|      40 | max precision | (95.57/47.14/63.13) |  1513.3 | 1.65e10 | \hspace{-1em} (94%)  | 85.75 |        -0.10 |              0 |
|      40 | recall        | (71.73/90.25/79.93) |  1403.9 | 1.33e10 | \hspace{-1em} (76%)  | 84.65 |        -1.20 |             14 |
|---------+---------------+---------------------+---------+---------+----------------------+-------+--------------+----------------|
|       ∞ | baseline      |                     |  1558.7 | 1.75e10 | \hspace{-1em} (100%) | 85.85 |         0.00 |              0 |
#+TBLFM: $4=$0;%.2e::$7=$6-85.85;p4%.2f

#+BEGIN_LaTeX
%}
\caption{Independence constraints reduce the work done by the CKY algorithm, trading off accuracy.}
\label{tbl:parse-results-linear}
\end{table*}
#+END_LaTeX

The results of running the parser on section 22 using the linear
classifier from Section \ref{sec:linear-classifier} are shown in
table \ref{tbl:parse-results-linear}. The table shows the total time
taken, the total times entering the inner loop, the F_1 and difference
from the baseline, and the number of times the parse failed using the
constraints. The baseline consisted of the same parser with the
sentence length threshold set to 1000. The time includes the time
spent reading in the constraints but not the time taken by the
classifier.

The parser with the independence constraints saves 35-38%
of the computation inside the CKY loop over the baseline,
corresponding to about 20% reduction in total time, at the cost of a
2-point drop in F-score. After increasing recall by making negative
instances for which the classifier assigned a low probability positive,
the parser reduced the work done inside the loop to less than half the
baseline, but accuracy also plummeted by 7 points.

*** Polynomial Kernel

A difference of 2 F_1 score is not small, but on the other hand it is
about by how much the unlexicalized Stanford Parser trails the Collins
parser, for example. However, as shown above in Section
\ref{sec:poly-classifier}, there is room to improve the linear
classifier through conjunctive features. As an indication of an upper
bound of the acheivable performance, we tried using the output of the
kernel classifier in the parser as above, while acknowledging that at
present the time needed to produce the classifier output dwarfs the
time needed to actually parse the test data.

#+BEGIN_LaTeX
\begin{table*}[tbp]
%\resizebox{12cm}{!}{
#+END_LaTeX

#+attr_latex: :center nil
| SentLen | Constraints   | (P/R/F_{1})         | time(s) |  #edges |                      |   F_1 |       | #failed parses |
|---------+---------------+---------------------+---------+---------+----------------------+-------+-------+----------------|
|       0 | default       | (92.17/88.91/90.51) |  1106.7 | 9.74e09 | \hspace{-1em} (56%)  | 84.85 | -1.00 |              6 |
|       0 | precision     | (92.95/86.43/89.58) |  1118.8 | 9.84e09 | \hspace{-1em} (56%)  | 85.12 | -0.73 |              4 |
|       0 | max precision | (94.22/79.63/86.31) |  1137.2 | 1.02e10 | \hspace{-1em} (58%)  | 85.42 | -0.43 |              2 |
|       0 | recall        | (88.16/91.32/89.71) |  1050.7 | 9.25e09 | \hspace{-1em} (53%)  | 84.05 | -1.80 |             33 |
|      20 | default       | (92.17/88.91/90.51) |  1070.7 | 1.02e10 | \hspace{-1em} (58%)  | 85.08 | -0.77 |              5 |
|      20 | precision     | (92.95/86.43/89.58) |  1172.4 | 1.03e10 | \hspace{-1em} (59%)  | 85.25 | -0.60 |              3 |
|      20 | max precision | (94.22/79.63/86.31) |  1092.4 | 1.06e10 | \hspace{-1em} (61%)  | 85.41 | -0.44 |              2 |
|      20 | recall        | (88.16/91.32/89.71) |  1088.3 | 9.68e09 | \hspace{-1em} (55%)  | 84.75 | -1.10 |              7 |
|      30 | default       | (92.17/88.91/90.51) |  1222.6 | 1.20e10 | \hspace{-1em} (69%)  | 85.57 | -0.28 |              1 |
|      30 | precision     | (92.95/86.43/89.58) |  1267.5 | 1.20e10 | \hspace{-1em} (69%)  | 85.62 | -0.23 |              1 |
|      30 | max precision | (94.22/79.63/86.31) |  1238.7 | 1.23e10 | \hspace{-1em} (70%)  | 85.65 | -0.20 |              1 |
|      30 | recall        | (88.16/91.32/89.71) |  1238.0 | 1.16e10 | \hspace{-1em} (66%)  | 85.44 | -0.41 |              2 |
|      40 | default       | (92.17/88.91/90.51) |  1465.4 | 1.49e10 | \hspace{-1em} (85%)  | 85.72 | -0.13 |              0 |
|      40 | precision     | (92.95/86.43/89.58) |  1353.3 | 1.49e10 | \hspace{-1em} (85%)  | 85.75 | -0.10 |              0 |
|      40 | max precision | (94.22/79.63/86.31) |  1570.2 | 1.50e10 | \hspace{-1em} (86%)  | 85.78 | -0.07 |              0 |
|      40 | recall        | (88.16/91.32/89.71) |  1489.7 | 1.47e10 | \hspace{-1em} (84%)  | 85.69 | -0.16 |              1 |
|---------+---------------+---------------------+---------+---------+----------------------+-------+-------+----------------|
|       ∞ | baseline      |                     |  1470.9 | 1.75e10 | \hspace{-1em} (100%) | 85.85 |  0.00 |              0 |
#+TBLFM: $4=$0;%.2e::$7=$6-85.85;p4%.2f

#+BEGIN_LaTeX
%}
\caption{The classifier using the polynomial kernel is much more accurate, leading to smaller loss in accuracy of the parser.}
\label{tbl:parse-results-poly}
\end{table*}
#+END_LaTeX

The results of running the parser on section 22 with the polynomial
classifier output are shown in table \ref{tbl:parse-results-poly}.
With the more accurate classifier, the parser is able to reduce the
necessary computation even further, by about 45%, while losing less
accuracy. With a high-precision threshold, the computation of the CKY
algorithm is reduced to less than 60% of the baseline, while losing
less than half a point F_1 score.

*** WSJ Section 23

To compare with previous work on parsing using the Penn Treebank, we
show the time and accuracy for parsing section 23, using both linear
and kernel classifier output, along with the baseline parser, below.
The times reported are the average of three runs each. The results
parallel those shown on the development data.

| parser   | time (s) |      |   F_1 |       |
|----------+----------+------+-------+-------|
| baseline |     1538 | 1.00 | 85.54 |  0.00 |
| linear   |     1106 | 1.39 | 83.55 | -1.99 |
| poly     |     1040 | 1.48 | 84.57 | -0.97 |
#+TBLFM: $3=1538/$2;%.2f::$5=$4-85.54;p4%.2f

** TODO add oracle results

* Related Work

There are several strains of research related to adding constraints to
the CKY chart. \cite{Roark2012} describes an approach using
finite-state taggers to decide whether each word in a sentence begins
or ends a multiword constituent and has a unary span or not. They show
that their tagger is able to achieve very high precision, reducing
parse time without negatively affecting accuracy (in fact, they report
a slight increase). Our approach is also a pipelined approach with a
classifier that makes a linear number of decisions per sentence;
however, each decision is made independently, and requires global
information to achieve high accuracy.

\cite{Bodenstab2011} proposes a classifier which directly decides for
each cell in the chart how many constituents should be created. Their
parser uses beam search with a FOM and a beam for each chart cell.

\cite{Yarmohammadi2014} proposes a concept of 'hedge' parsing, where
only spans below a certain length are allowed, and show how this
reduces the computation done by CKY. Their approach for segmenting a
sentence and parsing within each segment separately is similar to the
approach presented in this paper; however, their system does not create
spans of length larger than the threshold and thus doesn't follow the
original treebank annotation, while our approach is able to return the
original gold parse tree provided that the classifier does not output
a false positive.

* Conclusions

We have proposed an *independence* property of words in a sentence
derived from a parse tree, and shown how to use this property to
create top-down constraints which can be used to reduce the
computation done by the CKY algorithm. Then we demonstrated two
classifiers for identifying boundaries between independent words given
a sentence with only surface features, a linear classifier which is
fast but less accurate, and a classifier with a polynomial kernel
which is much more accurate but very slow. We then showed that a
commonly-used CFG parser can be made faster by using the output of
these classifiers to create top-down constraints at the cost of some
accuracy, which can be traded-off by varying the confidence threshold
of the classifier results.

Although the loss of accuracy when using the linear classifier is
currently too large to be practical, the performance of the kernel
classifier indicates that there is room for improvement by manually
adding conjunctive features to the linear classifier. Features based
on words as well as POS tags may also be beneficial. However, the
current approach has several weaknesses which should be addressed by
future research.

First, the top-down nature of the independence constraints does not
make a natural fit with the bottom-up CKY algorithm. In particular,
the binary nature of the rules in the grammar combined with the
bottom-up search means that the parser still ends up doing some
computation to create spans which violate the constraints, even though
it is prevented from completing such a span.

Second, the pipelined nature of the classifier means that it only has
access to POS tags and in particular is not able to make use of
information generated as the parser processes lower-level spans.

Third, the current classifier combines instances from different
syntactic structures into a single model. It is possible that training
multiple models on different types of sentences would result in a
better classifier.

#+BEGIN_LaTeX
\bibliographystyle{acl}
\bibliography{references}
#+END_LaTeX
